{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multunomiale Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I) Theory\n",
    "\n",
    "Naive Bayes models are a group of extremely fast and simple classification algorithms that are often suitable for very high-dimensional datasets.\n",
    "Because they are so fast and have so few tunable parameters, they end up being useful as a quick-and-dirty baseline for a classification problem.\n",
    "\n",
    "### 1) Equations\n",
    "\n",
    "Naive Bayes classifiers are built on Bayesian classification methods.\n",
    "These rely on Bayes's theorem, which is an equation describing the relationship of conditional probabilities of statistical quantities.\n",
    "In Bayesian classification, we're interested in finding the probability of a label $L$ given some observed features, which we can write as $P(L~|~{\\rm features})$.\n",
    "Bayes's theorem tells us how to express this in terms of quantities we can compute more directly:\n",
    "\n",
    "$$\n",
    "P(L~|~{\\rm features}) = \\frac{P({\\rm features}~|~L)P(L)}{P({\\rm features})}\n",
    "$$\n",
    "\n",
    "If we are trying to decide between two labels—let's call them $L_1$ and $L_2$—then one way to make this decision is to compute the ratio of the posterior probabilities for each label:\n",
    "\n",
    "$$\n",
    "\\frac{P(L_1~|~{\\rm features})}{P(L_2~|~{\\rm features})} = \\frac{P({\\rm features}~|~L_1)}{P({\\rm features}~|~L_2)}\\frac{P(L_1)}{P(L_2)}\n",
    "$$\n",
    "\n",
    "All we need now is some model by which we can compute $P({\\rm features}~|~L_i)$ for each label.\n",
    "Such a model is called a *generative model* because it specifies the hypothetical random process that generates the data.\n",
    "Specifying this generative model for each label is the main piece of the training of such a Bayesian classifier.\n",
    "The general version of such a training step is a very difficult task, but we can make it simpler through the use of some simplifying assumptions about the form of this model.\n",
    "\n",
    "This is where the \"naive\" in \"naive Bayes\" comes in: if we make very naive assumptions about the generative model for each label, we can find a rough approximation of the generative model for each class, and then proceed with the Bayesian classification.\n",
    "Different types of naive Bayes classifiers rest on different naive assumptions about the data, and we will examine a few of these in the following sections.\n",
    "\n",
    "### 2) Multinomial Naive Bayes\n",
    "\n",
    "The features are assumed to be generated from a simple multinomial distribution.\n",
    "The multinomial distribution describes the probability of observing counts among a number of categories, and thus multinomial naive Bayes is most appropriate for features that represent counts or count rates.\n",
    "\n",
    "One place where multinomial naive Bayes is often used is in text classification, where the features are related to word counts or frequencies within the documents to be classified.\n",
    "We discussed the extraction of such features from text in [Feature Engineering](05.04-Feature-Engineering.ipynb); here we will use the sparse word count features from the 20 Newsgroups corpus made available through Scikit-Learn to show how we might classify these short documents into categories.\n",
    "\n",
    "In order to use this data for machine learning, we need to be able to convert the content of each string into a vector of numbers.\n",
    "For this we will use the TF-IDF vectorizer (introduced in [Feature Engineering](05.04-Feature-Engineering.ipynb)), and create a pipeline that attaches it to a multinomial naive Bayes classifier:\n",
    "\n",
    "## When to Use Naive Bayes\n",
    "\n",
    "Because naive Bayes classifiers make such stringent assumptions about data, they will generally not perform as well as more complicated models.\n",
    "That said, they have several advantages:\n",
    "\n",
    "- They are fast for both training and prediction.\n",
    "- They provide straightforward probabilistic prediction.\n",
    "- They are often easily interpretable.\n",
    "- They have few (if any) tunable parameters.\n",
    "\n",
    "These advantages mean a naive Bayes classifier is often a good choice as an initial baseline classification.\n",
    "If it performs suitably, then congratulations: you have a very fast, very interpretable classifier for your problem.\n",
    "If it does not perform well, then you can begin exploring more sophisticated models, with some baseline knowledge of how well they should perform.\n",
    "\n",
    "Naive Bayes classifiers tend to perform especially well in the following situations:\n",
    "\n",
    "- When the naive assumptions actually match the data (very rare in practice)\n",
    "- For very well-separated categories, when model complexity is less important\n",
    "- For very high-dimensional data, when model complexity is less important\n",
    "\n",
    "The last two points seem distinct, but they actually are related: as the dimensionality of a dataset grows, it is much less likely for any two points to be found close together (after all, they must be close in *every single dimension* to be close overall).\n",
    "This means that clusters in high dimensions tend to be more separated, on average, than clusters in low dimensions, assuming the new dimensions actually add information.\n",
    "For this reason, simplistic classifiers like the ones discussed here tend to work as well or better than more complicated classifiers as the dimensionality grows: once you have enough data, even a simple model can be very powerful.\n",
    "\n",
    "### 3) Conclusion\n",
    "\n",
    "Now that we have predicted the labels for the test data, we can evaluate them to learn about the performance of the estimator.\n",
    "For example, let's take a look at the confusion matrix between the true and predicted labels for the test data (see the following figure):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II) Python implementation\n",
    "\n",
    "### 1) Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code_produit</th>\n",
       "      <th>Secteur</th>\n",
       "      <th>Ingrédient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>450</td>\n",
       "      <td>Produits laitiers et desserts frais</td>\n",
       "      <td>lait_ecreme_reconstitue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>450</td>\n",
       "      <td>Produits laitiers et desserts frais</td>\n",
       "      <td>sucre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>450</td>\n",
       "      <td>Produits laitiers et desserts frais</td>\n",
       "      <td>fruit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>450</td>\n",
       "      <td>Produits laitiers et desserts frais</td>\n",
       "      <td>creme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>450</td>\n",
       "      <td>Produits laitiers et desserts frais</td>\n",
       "      <td>epaississants</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Code_produit                              Secteur               Ingrédient\n",
       "0           450  Produits laitiers et desserts frais  lait_ecreme_reconstitue\n",
       "1           450  Produits laitiers et desserts frais                    sucre\n",
       "2           450  Produits laitiers et desserts frais                    fruit\n",
       "3           450  Produits laitiers et desserts frais                    creme\n",
       "4           450  Produits laitiers et desserts frais            epaississants"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r'C:\\Users\\Thomas Aujoux\\Documents\\GitHub\\food-classification\\data_preparation\\clean_.csv')\n",
    "df = df[[\"Code_produit\", \"Secteur\", \"Ingrédient\"]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df.groupby(['Code_produit', 'Secteur'])['Ingrédient'].agg(lambda col: ' '.join(col)).reset_index(name='Ingrédient')\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "coun_vect = CountVectorizer(token_pattern='\\\\b(\\\\w+[\\\\.,%_1234567890:()]?\\\\w+)\\\\b')\n",
    "count_matrix = coun_vect.fit_transform(df_new['Ingrédient'])\n",
    "count_array = count_matrix.toarray()\n",
    "df_vect = pd.DataFrame(data=count_array,columns = coun_vect.get_feature_names_out())\n",
    "new_df = pd.concat([df_new[[\"Code_produit\", \"Secteur\"]], df_vect], axis=1)\n",
    "new_df = new_df.drop(['_ananas', '_b1,_b9', '_b1,_b9_et_provitamine_a', '_b12', '_caillettes_de_boeuf_en_proportions_naturelles', '_carotte,_potiron_et_spiruline', '_d_avoine,_de_riz_et_d_epeautre', '_d_orge_et_de_riz', '_de_cassis_et_de_mure', '_de_cuivre', '_de_cuivre_et_de_manganese', '_de_matiere_grasse', '_de_matieres_grasses_au_lait_demi_ecreme_pasteurise', '_de_mg', '_de_thym,_de_laurier', '_e', '_gr', '_lb.rhamnosus', '_maigre_de_tete,_viande_et_couenne_de_porc', '_mg', '_paprika', '_provitamine_a', '_rooibos_et_du_melange_de_13_plantes_ricola', '_tournesol', '_vanille'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code_produit</th>\n",
       "      <th>Secteur</th>\n",
       "      <th>3_poivres</th>\n",
       "      <th>abondance_aop</th>\n",
       "      <th>abricot</th>\n",
       "      <th>abricot_de_provence</th>\n",
       "      <th>abricot_deshydrate</th>\n",
       "      <th>abricot_lyophilise</th>\n",
       "      <th>abricot_nectarine</th>\n",
       "      <th>abricot_orange</th>\n",
       "      <th>...</th>\n",
       "      <th>zestes_d_orange</th>\n",
       "      <th>zestes_d_oranges</th>\n",
       "      <th>zestes_de_citron</th>\n",
       "      <th>zestes_de_citron_deshydrates</th>\n",
       "      <th>zestes_de_citron_jaune</th>\n",
       "      <th>zestes_de_citron_vert</th>\n",
       "      <th>zestes_de_citrons</th>\n",
       "      <th>zestes_de_mandarine</th>\n",
       "      <th>zinc</th>\n",
       "      <th>zygochlamys_patagonica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>450</td>\n",
       "      <td>Produits laitiers et desserts frais</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>453</td>\n",
       "      <td>Produits laitiers et desserts frais</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>455</td>\n",
       "      <td>Produits laitiers et desserts frais</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>456</td>\n",
       "      <td>Produits laitiers et desserts frais</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>460</td>\n",
       "      <td>Produits laitiers et desserts frais</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 12763 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Code_produit                              Secteur  3_poivres  \\\n",
       "0           450  Produits laitiers et desserts frais          0   \n",
       "1           453  Produits laitiers et desserts frais          0   \n",
       "2           455  Produits laitiers et desserts frais          0   \n",
       "3           456  Produits laitiers et desserts frais          0   \n",
       "4           460  Produits laitiers et desserts frais          0   \n",
       "\n",
       "   abondance_aop  abricot  abricot_de_provence  abricot_deshydrate  \\\n",
       "0              0        0                    0                   0   \n",
       "1              0        0                    0                   0   \n",
       "2              0        0                    0                   0   \n",
       "3              0        0                    0                   0   \n",
       "4              0        0                    0                   0   \n",
       "\n",
       "   abricot_lyophilise  abricot_nectarine  abricot_orange  ...  \\\n",
       "0                   0                  0               0  ...   \n",
       "1                   0                  0               0  ...   \n",
       "2                   0                  0               0  ...   \n",
       "3                   0                  0               0  ...   \n",
       "4                   0                  0               0  ...   \n",
       "\n",
       "   zestes_d_orange  zestes_d_oranges  zestes_de_citron  \\\n",
       "0                0                 0                 0   \n",
       "1                0                 0                 0   \n",
       "2                0                 0                 0   \n",
       "3                0                 0                 0   \n",
       "4                0                 0                 0   \n",
       "\n",
       "   zestes_de_citron_deshydrates  zestes_de_citron_jaune  \\\n",
       "0                             0                       0   \n",
       "1                             0                       0   \n",
       "2                             0                       0   \n",
       "3                             0                       0   \n",
       "4                             0                       0   \n",
       "\n",
       "   zestes_de_citron_vert  zestes_de_citrons  zestes_de_mandarine  zinc  \\\n",
       "0                      0                  0                    0     0   \n",
       "1                      0                  0                    0     0   \n",
       "2                      0                  0                    0     0   \n",
       "3                      0                  0                    0     0   \n",
       "4                      0                  0                    0     0   \n",
       "\n",
       "   zygochlamys_patagonica  \n",
       "0                       0  \n",
       "1                       0  \n",
       "2                       0  \n",
       "3                       0  \n",
       "4                       0  \n",
       "\n",
       "[5 rows x 12763 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = new_df[[\"Secteur\"]]\n",
    "df_features = new_df.drop([\"Code_produit\", \"Secteur\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Secteur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Produits laitiers et desserts frais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Produits laitiers et desserts frais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Produits laitiers et desserts frais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Produits laitiers et desserts frais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Produits laitiers et desserts frais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65231</th>\n",
       "      <td>Sirops et boissons concentrees a diluer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65232</th>\n",
       "      <td>Sirops et boissons concentrees a diluer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65233</th>\n",
       "      <td>Sirops et boissons concentrees a diluer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65234</th>\n",
       "      <td>Sirops et boissons concentrees a diluer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65235</th>\n",
       "      <td>Sirops et boissons concentrees a diluer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65236 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Secteur\n",
       "0          Produits laitiers et desserts frais\n",
       "1          Produits laitiers et desserts frais\n",
       "2          Produits laitiers et desserts frais\n",
       "3          Produits laitiers et desserts frais\n",
       "4          Produits laitiers et desserts frais\n",
       "...                                        ...\n",
       "65231  Sirops et boissons concentrees a diluer\n",
       "65232  Sirops et boissons concentrees a diluer\n",
       "65233  Sirops et boissons concentrees a diluer\n",
       "65234  Sirops et boissons concentrees a diluer\n",
       "65235  Sirops et boissons concentrees a diluer\n",
       "\n",
       "[65236 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Thomas Aujoux\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "lda = LinearDiscriminantAnalysis(n_components=30)\n",
    "X_lda = lda.fit_transform(df_features, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(X_lda)\n",
    "X\n",
    "X.to_csv(r'C:\\Users\\Thomas Aujoux\\Documents\\GitHub\\food-classification\\data_preparation\\clean_lda.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.826776</td>\n",
       "      <td>0.375907</td>\n",
       "      <td>0.540275</td>\n",
       "      <td>0.680575</td>\n",
       "      <td>0.673852</td>\n",
       "      <td>0.614784</td>\n",
       "      <td>0.536734</td>\n",
       "      <td>0.537060</td>\n",
       "      <td>0.601697</td>\n",
       "      <td>0.557360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.477933</td>\n",
       "      <td>0.611405</td>\n",
       "      <td>0.324975</td>\n",
       "      <td>0.298807</td>\n",
       "      <td>0.307487</td>\n",
       "      <td>0.409955</td>\n",
       "      <td>0.357855</td>\n",
       "      <td>0.814064</td>\n",
       "      <td>0.789872</td>\n",
       "      <td>0.806784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.848350</td>\n",
       "      <td>0.383474</td>\n",
       "      <td>0.556013</td>\n",
       "      <td>0.665059</td>\n",
       "      <td>0.757387</td>\n",
       "      <td>0.604570</td>\n",
       "      <td>0.450661</td>\n",
       "      <td>0.559762</td>\n",
       "      <td>0.575034</td>\n",
       "      <td>0.587137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.478419</td>\n",
       "      <td>0.608203</td>\n",
       "      <td>0.314226</td>\n",
       "      <td>0.288401</td>\n",
       "      <td>0.320128</td>\n",
       "      <td>0.414979</td>\n",
       "      <td>0.361924</td>\n",
       "      <td>0.808490</td>\n",
       "      <td>0.786682</td>\n",
       "      <td>0.813843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.846487</td>\n",
       "      <td>0.374543</td>\n",
       "      <td>0.534325</td>\n",
       "      <td>0.706427</td>\n",
       "      <td>0.766920</td>\n",
       "      <td>0.634199</td>\n",
       "      <td>0.481443</td>\n",
       "      <td>0.611103</td>\n",
       "      <td>0.647848</td>\n",
       "      <td>0.475575</td>\n",
       "      <td>...</td>\n",
       "      <td>0.488682</td>\n",
       "      <td>0.614764</td>\n",
       "      <td>0.293649</td>\n",
       "      <td>0.271874</td>\n",
       "      <td>0.319739</td>\n",
       "      <td>0.452931</td>\n",
       "      <td>0.374703</td>\n",
       "      <td>0.818642</td>\n",
       "      <td>0.789345</td>\n",
       "      <td>0.818805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.846760</td>\n",
       "      <td>0.383158</td>\n",
       "      <td>0.569927</td>\n",
       "      <td>0.651972</td>\n",
       "      <td>0.749956</td>\n",
       "      <td>0.582726</td>\n",
       "      <td>0.444564</td>\n",
       "      <td>0.536722</td>\n",
       "      <td>0.542191</td>\n",
       "      <td>0.648829</td>\n",
       "      <td>...</td>\n",
       "      <td>0.473714</td>\n",
       "      <td>0.614039</td>\n",
       "      <td>0.322550</td>\n",
       "      <td>0.291800</td>\n",
       "      <td>0.330022</td>\n",
       "      <td>0.418990</td>\n",
       "      <td>0.361539</td>\n",
       "      <td>0.809292</td>\n",
       "      <td>0.786037</td>\n",
       "      <td>0.796477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.846579</td>\n",
       "      <td>0.403201</td>\n",
       "      <td>0.558620</td>\n",
       "      <td>0.657233</td>\n",
       "      <td>0.744293</td>\n",
       "      <td>0.609315</td>\n",
       "      <td>0.428394</td>\n",
       "      <td>0.545531</td>\n",
       "      <td>0.568100</td>\n",
       "      <td>0.582572</td>\n",
       "      <td>...</td>\n",
       "      <td>0.483666</td>\n",
       "      <td>0.609687</td>\n",
       "      <td>0.308987</td>\n",
       "      <td>0.285086</td>\n",
       "      <td>0.319751</td>\n",
       "      <td>0.423994</td>\n",
       "      <td>0.362920</td>\n",
       "      <td>0.807958</td>\n",
       "      <td>0.786319</td>\n",
       "      <td>0.810368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65231</th>\n",
       "      <td>0.847246</td>\n",
       "      <td>0.405359</td>\n",
       "      <td>0.534633</td>\n",
       "      <td>0.556427</td>\n",
       "      <td>0.673972</td>\n",
       "      <td>0.565089</td>\n",
       "      <td>0.355684</td>\n",
       "      <td>0.428413</td>\n",
       "      <td>0.562885</td>\n",
       "      <td>0.496835</td>\n",
       "      <td>...</td>\n",
       "      <td>0.501672</td>\n",
       "      <td>0.598822</td>\n",
       "      <td>0.279688</td>\n",
       "      <td>0.279340</td>\n",
       "      <td>0.311893</td>\n",
       "      <td>0.449590</td>\n",
       "      <td>0.353149</td>\n",
       "      <td>0.807004</td>\n",
       "      <td>0.786520</td>\n",
       "      <td>0.801416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65232</th>\n",
       "      <td>0.845879</td>\n",
       "      <td>0.383110</td>\n",
       "      <td>0.492496</td>\n",
       "      <td>0.514950</td>\n",
       "      <td>0.668515</td>\n",
       "      <td>0.566440</td>\n",
       "      <td>0.378346</td>\n",
       "      <td>0.413015</td>\n",
       "      <td>0.561224</td>\n",
       "      <td>0.501517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.479155</td>\n",
       "      <td>0.697778</td>\n",
       "      <td>0.311653</td>\n",
       "      <td>0.258194</td>\n",
       "      <td>0.328503</td>\n",
       "      <td>0.412150</td>\n",
       "      <td>0.508824</td>\n",
       "      <td>0.832622</td>\n",
       "      <td>0.813545</td>\n",
       "      <td>0.798122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65233</th>\n",
       "      <td>0.846169</td>\n",
       "      <td>0.391137</td>\n",
       "      <td>0.472136</td>\n",
       "      <td>0.550051</td>\n",
       "      <td>0.676781</td>\n",
       "      <td>0.573077</td>\n",
       "      <td>0.403685</td>\n",
       "      <td>0.414124</td>\n",
       "      <td>0.564231</td>\n",
       "      <td>0.494826</td>\n",
       "      <td>...</td>\n",
       "      <td>0.506036</td>\n",
       "      <td>0.697943</td>\n",
       "      <td>0.282325</td>\n",
       "      <td>0.233808</td>\n",
       "      <td>0.304402</td>\n",
       "      <td>0.431453</td>\n",
       "      <td>0.593527</td>\n",
       "      <td>0.849838</td>\n",
       "      <td>0.826749</td>\n",
       "      <td>0.790733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65234</th>\n",
       "      <td>0.845887</td>\n",
       "      <td>0.380957</td>\n",
       "      <td>0.508517</td>\n",
       "      <td>0.552654</td>\n",
       "      <td>0.697729</td>\n",
       "      <td>0.533389</td>\n",
       "      <td>0.395061</td>\n",
       "      <td>0.380249</td>\n",
       "      <td>0.567195</td>\n",
       "      <td>0.455830</td>\n",
       "      <td>...</td>\n",
       "      <td>0.499825</td>\n",
       "      <td>0.764371</td>\n",
       "      <td>0.271982</td>\n",
       "      <td>0.178732</td>\n",
       "      <td>0.303127</td>\n",
       "      <td>0.407247</td>\n",
       "      <td>0.567496</td>\n",
       "      <td>0.870472</td>\n",
       "      <td>0.832815</td>\n",
       "      <td>0.806230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65235</th>\n",
       "      <td>0.846315</td>\n",
       "      <td>0.372890</td>\n",
       "      <td>0.510569</td>\n",
       "      <td>0.543988</td>\n",
       "      <td>0.689308</td>\n",
       "      <td>0.569702</td>\n",
       "      <td>0.370193</td>\n",
       "      <td>0.416185</td>\n",
       "      <td>0.556258</td>\n",
       "      <td>0.496662</td>\n",
       "      <td>...</td>\n",
       "      <td>0.482691</td>\n",
       "      <td>0.815488</td>\n",
       "      <td>0.282509</td>\n",
       "      <td>0.187054</td>\n",
       "      <td>0.320161</td>\n",
       "      <td>0.430962</td>\n",
       "      <td>0.594724</td>\n",
       "      <td>0.862008</td>\n",
       "      <td>0.831837</td>\n",
       "      <td>0.806310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65236 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6   \\\n",
       "0      0.826776  0.375907  0.540275  0.680575  0.673852  0.614784  0.536734   \n",
       "1      0.848350  0.383474  0.556013  0.665059  0.757387  0.604570  0.450661   \n",
       "2      0.846487  0.374543  0.534325  0.706427  0.766920  0.634199  0.481443   \n",
       "3      0.846760  0.383158  0.569927  0.651972  0.749956  0.582726  0.444564   \n",
       "4      0.846579  0.403201  0.558620  0.657233  0.744293  0.609315  0.428394   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "65231  0.847246  0.405359  0.534633  0.556427  0.673972  0.565089  0.355684   \n",
       "65232  0.845879  0.383110  0.492496  0.514950  0.668515  0.566440  0.378346   \n",
       "65233  0.846169  0.391137  0.472136  0.550051  0.676781  0.573077  0.403685   \n",
       "65234  0.845887  0.380957  0.508517  0.552654  0.697729  0.533389  0.395061   \n",
       "65235  0.846315  0.372890  0.510569  0.543988  0.689308  0.569702  0.370193   \n",
       "\n",
       "             7         8         9   ...        20        21        22  \\\n",
       "0      0.537060  0.601697  0.557360  ...  0.477933  0.611405  0.324975   \n",
       "1      0.559762  0.575034  0.587137  ...  0.478419  0.608203  0.314226   \n",
       "2      0.611103  0.647848  0.475575  ...  0.488682  0.614764  0.293649   \n",
       "3      0.536722  0.542191  0.648829  ...  0.473714  0.614039  0.322550   \n",
       "4      0.545531  0.568100  0.582572  ...  0.483666  0.609687  0.308987   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "65231  0.428413  0.562885  0.496835  ...  0.501672  0.598822  0.279688   \n",
       "65232  0.413015  0.561224  0.501517  ...  0.479155  0.697778  0.311653   \n",
       "65233  0.414124  0.564231  0.494826  ...  0.506036  0.697943  0.282325   \n",
       "65234  0.380249  0.567195  0.455830  ...  0.499825  0.764371  0.271982   \n",
       "65235  0.416185  0.556258  0.496662  ...  0.482691  0.815488  0.282509   \n",
       "\n",
       "             23        24        25        26        27        28        29  \n",
       "0      0.298807  0.307487  0.409955  0.357855  0.814064  0.789872  0.806784  \n",
       "1      0.288401  0.320128  0.414979  0.361924  0.808490  0.786682  0.813843  \n",
       "2      0.271874  0.319739  0.452931  0.374703  0.818642  0.789345  0.818805  \n",
       "3      0.291800  0.330022  0.418990  0.361539  0.809292  0.786037  0.796477  \n",
       "4      0.285086  0.319751  0.423994  0.362920  0.807958  0.786319  0.810368  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "65231  0.279340  0.311893  0.449590  0.353149  0.807004  0.786520  0.801416  \n",
       "65232  0.258194  0.328503  0.412150  0.508824  0.832622  0.813545  0.798122  \n",
       "65233  0.233808  0.304402  0.431453  0.593527  0.849838  0.826749  0.790733  \n",
       "65234  0.178732  0.303127  0.407247  0.567496  0.870472  0.832815  0.806230  \n",
       "65235  0.187054  0.320161  0.430962  0.594724  0.862008  0.831837  0.806310  \n",
       "\n",
       "[65236 rows x 30 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler #fixed import\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_ = scaler.fit_transform(X)\n",
    "X_ = pd.DataFrame(X_)\n",
    "X_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance explained: 99.99999999999999\n"
     ]
    }
   ],
   "source": [
    "exp_var = sum(lda.explained_variance_ratio_ * 100)\n",
    "print('Variance explained:', exp_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnYAAAHWCAYAAAD6oMSKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABW50lEQVR4nO3deVjU5d7H8c+Asm/iAmgImHvivuSS5nLELFOztCTFFuskmmulJ9csNTU1Ox63UqtHszppZaZm5L5vkSZuiEuGUJoQIKjwe/7gcR5HXBgYtvH9uq65Lua33POdGdSP9+9337fJMAxDAAAAKPEciroAAAAA2AbBDgAAwE4Q7AAAAOwEwQ4AAMBOEOwAAADsBMEOAADAThDsAAAA7ATBDgAAwE6UKuoCioOsrCz9/vvv8vT0lMlkKupyAAAAzAzD0N9//62KFSvKweHOfXIEO0m///67AgMDi7oMAACA2zp79qzuu+++Ox5DsJPk6ekpKfsD8/LyKuJqAAAA/l9ycrICAwPNeeVOCHaS+fKrl5cXwQ4AABRLubldjMETAAAAdoJgBwAAYCcIdgAAAHaCe+xyKSsrS1euXCnqMgAUM6VLl5ajo2NRlwEAkgh2uXLlyhXFxcUpKyurqEsBUAz5+PjI39+feTABFDmC3V0YhqH4+Hg5OjoqMDDwrhMDArh3GIahtLQ0JSYmSpICAgKKuCIA9zqC3V1cu3ZNaWlpqlixotzc3Iq6HADFjKurqyQpMTFRFSpU4LIsgCJF99NdZGZmSpKcnJyKuBIAxdX1//RdvXq1iCsBcK8j2OUS984AuB3+fgBQXBDsUGRMJpO+/vrrYtNOUevXr5+6deuW6+NPnTolk8mkn3/+ucBquq6oPuPCfI8AYA8Idnbs/PnzGjRokKpUqSJnZ2cFBgaqS5cuioqKKurS8mT8+PGqX79+ju3x8fF65JFHCr+gIhYYGKj4+HjVqVOnqEspMPfCewQAW2LwhJ06deqUWrZsKR8fH02bNk2hoaG6evWq1q1bp8jISB05cqSoS7QZf3//oi6hSDg6Otr1e79y5YqcnJzs+j0CgK0VaY/d5s2b1aVLF1WsWPGWl3oMw9DYsWMVEBAgV1dXdejQQcePH7c45uLFiwoPD5eXl5d8fHz0wgsvKCUlpRDfRfE0YMAAmUwm7d69Wz169FD16tX1wAMPaNiwYdq5c6ekW1/munTpkkwmkzZu3ChJ2rhxo0wmk9atW6cGDRrI1dVV7dq1U2JiotasWaNatWrJy8tLvXv3Vlpamrmd4OBgzZo1y6Km+vXra/z48bet+Y033lD16tXl5uamKlWqaMyYMeab0ZcsWaIJEyYoOjpaJpNJJpNJS5YskWR5mbBFixZ64403LNr9448/VLp0aW3evFmSlJGRoREjRqhSpUpyd3dXs2bNzO/3di5duqQXX3xR5cuXl5eXl9q1a6fo6Ghz+/7+/po0aZL5+O3bt8vJycncO3q9t3H+/PkKDAyUm5ubevbsqaSkpNu+5tq1a9WqVSv5+PiobNmyeuyxxxQbG2vef/P3d/27ioqKUuPGjeXm5qYWLVro6NGjFu1+8803atiwoVxcXFSlShVNmDBB165dM+8/fvy4WrduLRcXF9WuXVvr16+/42ezYMECVaxYMcc8j127dtXzzz8vSYqNjVXXrl3l5+cnDw8PNWnSRD/++KPF8cHBwZo4caL69u0rLy8vvfTSSzneY2Zmpl544QWFhITI1dVVNWrU0Pvvv2/RzvVL2tOnT1dAQIDKli2ryMhIi4ENGRkZeuONNxQYGChnZ2dVrVpVH330kXn/oUOH9Mgjj8jDw0N+fn7q06eP/vzzzzt+DgBQHBRpsEtNTVW9evU0Z86cW+6fOnWqZs+erXnz5mnXrl1yd3dXWFiY0tPTzceEh4fr119/1fr16/Xdd99p8+bNeumllwrrLRRLFy9e1Nq1axUZGSl3d/cc+318fKxuc/z48fr3v/+t7du36+zZs+rZs6dmzZqlZcuWafXq1frhhx/0wQcf5KtuT09PLVmyRIcPH9b777+vhQsXaubMmZKkXr16afjw4XrggQcUHx+v+Ph49erVK0cb4eHhWr58uQzDMG/7/PPPVbFiRT300EOSpIEDB2rHjh1avny5fvnlFz311FPq1KlTjv803Oipp54yh9l9+/apYcOGat++vS5evKjy5ctr0aJFGj9+vPbu3au///5bffr00cCBA9W+fXtzGydOnNAXX3yhVatWae3atTpw4IAGDBhw29dMTU3VsGHDtHfvXkVFRcnBwUHdu3e/60TZb775pt577z3t3btXpUqVMocrSdqyZYv69u2rwYMH6/Dhw5o/f76WLFmid955R1L2CitPPPGEnJyctGvXLs2bNy9HUL7VZ3PhwgVt2LDBvO3672B4eLgkKSUlRZ07d1ZUVJQOHDigTp06qUuXLjpz5oxFW9OnT1e9evV04MABjRkzJsdrZWVl6b777tOXX36pw4cPa+zYsfrXv/6lL774wuK4DRs2KDY2Vhs2bNDHH3+sJUuWmP8jIEl9+/bVZ599ptmzZysmJkbz58+Xh4eHpOwQ365dOzVo0EB79+7V2rVrlZCQoJ49e97xcwCAYsEoJiQZK1euND/Pysoy/P39jWnTppm3Xbp0yXB2djY+++wzwzAM4/Dhw4YkY8+ePeZj1qxZY5hMJuPcuXO5fu2kpCRDkpGUlJRj3+XLl43Dhw8bly9fvl6YYaSkFM0jKytX72fXrl2GJGPFihV3PC4uLs6QZBw4cMC87a+//jIkGRs2bDAMwzA2bNhgSDJ+/PFH8zGTJ082JBmxsbHmbS+//LIRFhZmfh4UFGTMnDnT4vXq1atnjBs3zvz85u/8ZtOmTTMaNWpkfj5u3DijXr16OY67sZ3ExESjVKlSxubNm837mzdvbrzxxhuGYRjG6dOnDUdHxxy/H+3btzdGjRp1yzq2bNlieHl5Genp6Rbb77//fmP+/Pnm5wMGDDCqV69u9O7d2wgNDbU4fty4cYajo6Px22+/mbetWbPGcHBwMOLj4w3DMIyIiAija9eut/08/vjjD0OScfDgQcMwcn5/t/quVq9ebUgy//62b9/emDRpkkW7n376qREQEGAYhmGsW7fOKFWqlMXns2bNmrt+V127djWef/558/P58+cbFStWNDIzM297zgMPPGB88MEH5udBQUFGt27dLI651e/ozSIjI40ePXqYn0dERBhBQUHGtWvXzNueeuopo1evXoZhGMbRo0cNScb69etv2d7EiRONjh07Wmw7e/asIck4evToLc/J8fcEgJIlt/+25/LfYVu7U065WbG9xy4uLk7nz59Xhw4dzNu8vb3VrFkz7dixQ08//bR27NghHx8fNW7c2HxMhw4d5ODgoF27dql79+63bDsjI0MZGRnm58nJybkvLC1N+r//2Re6lBTpFj1wNzNu6K2ylbp165p/9vPzM18uvXHb7t278/Uan3/+uWbPnq3Y2FilpKTo2rVr8vLysqqN8uXLq2PHjlq6dKkeeughxcXFaceOHZo/f74k6eDBg8rMzFT16tUtzsvIyFDZsmVv2WZ0dLRSUlJy7L98+bLFpdHp06erTp06+vLLL7Vv3z45OztbHF+5cmVVqlTJ/Lx58+bKysrS0aNHb3kf2fHjxzV27Fjt2rVLf/75p7mn7syZM3ccTHDjd3V9JYTExERVrlxZ0dHR2rZtm7mHTsq+vJmenq60tDTFxMQoMDBQFStWtKjzbsLDw9W/f3/95z//kbOzs5YuXaqnn37avFJLSkqKxo8fr9WrVys+Pl7Xrl3T5cuXc/TY3fhn+XbmzJmjRYsW6cyZM7p8+bKuXLmSY1DNAw88YDFRcEBAgA4ePChJ+vnnn+Xo6Kg2bdrcsv3o6Ght2LDB3IN3o9jY2By/OwBKOMOQWrWStm+/+7G5/He4KBXbYHf+/HlJ2YHhRn5+fuZ958+fV4UKFSz2lypVSr6+vuZjbmXy5MmaMGGCjSsuPqpVqyaTyXTXARLX/9G9MQjeboLV0qVLm382mUwWz69vu/ESoYODQ46AeafJW3fs2KHw8HBNmDBBYWFh8vb21vLly/Xee+/d8T3cSnh4uF599VV98MEHWrZsmUJDQxUaGiopO2A4Ojpq3759OVYIuNU/5NfPCQgIuOV9eDde1o6NjdXvv/+urKwsnTp1yvyaedWlSxcFBQVp4cKF5nvY6tSpoytXrtzxvJu/K0nm7yYlJUUTJkzQE088keM8FxeXfNVqGIZWr16tJk2aaMuWLebL6JI0YsQIrV+/XtOnT1fVqlXl6uqqJ598Msd7udWtAzdavny5RowYoffee0/NmzeXp6enpk2bpl27dlkcd6ffz+srRdxOSkqKunTponfffTfHPpYMA4ohw8judMmr1NTchboSotgGu4I0atQoDRs2zPw8OTlZgYGBuTvZzS07sReFXC5p5uvrq7CwMM2ZM0evvvpqjn8sL126JB8fH5UvX15S9nQhDRo0kCSbzRdWvnx5xcfHm58nJycrLi7utsdv375dQUFBevPNN83bTp8+bXGMk5OTeSWQO+natateeuklrV27VsuWLVPfvn3N+xo0aKDMzEwlJiaa77m7m4YNG+r8+fMqVaqUgoODb3nMlStX9Oyzz6pXr16qUaOGXnzxRR08eNDiPx5nzpzR77//bu4N27lzpxwcHFSjRo0c7V24cEFHjx7VwoULzXVu3bo1V/Xe7b0cPXpUVatWveX+WrVq6ezZs4qPjzeHmOuDbe7ExcVFTzzxhJYuXaoTJ06oRo0aatiwoXn/tm3b1K9fP3MvekpKik6dOmV1/du2bVOLFi0s7k28sdc0N0JDQ5WVlaVNmzZZXBG4rmHDhvrqq68UHBysUqXuyb8igZLDmt623EhIuHOPXAlYWrTYzmN3/dJUQkKCxfaEhATzPn9/f/Pi29ddu3ZNFy9evOMUCc7OzvLy8rJ45JrJlP2lF8XDitnt58yZo8zMTDVt2lRfffWVjh8/rpiYGM2ePdt8ac3V1VUPPvigpkyZopiYGG3atEmjR4/O/WdxB+3atdOnn36qLVu26ODBg4qIiLjjGprVqlXTmTNntHz5csXGxmr27NlauXKlxTHBwcGKi4vTzz//rD///NPicvqN3N3d1a1bN40ZM0YxMTF65plnzPuqV6+u8PBw9e3bVytWrFBcXJx2796tyZMna/Xq1bdsr0OHDmrevLm6deumH374QadOndL27dv15ptvau/evZKyBywkJSVp9uzZ5tG9Nw5akLLDT0REhKKjo7Vlyxa9+uqr6tmz5y1/V8uUKaOyZctqwYIFOnHihH766SeL/4zk1dixY/XJJ59owoQJ+vXXXxUTE6Ply5ebv/cOHTqoevXqFnXeGLbvJDw8XKtXr9aiRYvMgyauq1atmlasWKGff/5Z0dHR6t27910HgdxKtWrVtHfvXq1bt07Hjh3TmDFjtGfPHqvaCA4OVkREhJ5//nl9/fXXiouL08aNG80DMCIjI3Xx4kU988wz2rNnj2JjY7Vu3To999xzufqPBYBClJZmu1DXsqVUvrzN/h0uKsU22IWEhMjf399iMt3k5GTt2rXLHEyaN2+uS5cuad++feZjfvrpJ2VlZalZs2aFXnNxUqVKFe3fv19t27bV8OHDVadOHf3jH/9QVFSU5s6daz5u0aJFunbtmho1aqQhQ4bo7bfftsnrjxo1Sm3atNFjjz2mRx99VN26ddP9999/2+Mff/xxDR06VAMHDlT9+vW1ffv2HKMie/TooU6dOqlt27YqX768Pvvss9u2Fx4erujoaD300EOqXLmyxb7Fixerb9++Gj58uGrUqKFu3bppz549OY67zmQy6fvvv1fr1q313HPPqXr16nr66ad1+vRp+fn5aePGjZo1a5Y+/fRTeXl5ycHBwRxqb/ysq1atqieeeEKdO3dWx44dVbduXf3nP/+55Ws6ODho+fLl2rdvn+rUqaOhQ4dq2rRpt32/uRUWFqbvvvtOP/zwg5o0aaIHH3xQM2fOVFBQkPl1V65cqcuXL6tp06Z68cUXLe7Hu5N27drJ19dXR48eVe/evS32zZgxQ2XKlFGLFi3UpUsXhYWFWfTo5dbLL7+sJ554Qr169VKzZs104cKFO44svp25c+fqySef1IABA1SzZk31799fqampkqSKFStq27ZtyszMVMeOHRUaGqohQ4bIx8fHfPsCgGIoISH7ilpeH1u2lIjgdjcmoyDutM+llJQUnThxQlL2JbIZM2aobdu28vX1VeXKlfXuu+9qypQp+vjjjxUSEqIxY8bol19+0eHDh833Az3yyCNKSEjQvHnzdPXqVT333HNq3Lixli1blus6kpOT5e3traSkpBy9d+np6YqLi1NISEi+7kHCvW38+PH6+uuvWRrLTvH3BFBEUlP/f0BjCRjYkFd3yik3K9IbSPbu3au2bduan1+/1BQREaElS5bo9ddfV2pqql566SVdunRJrVq10tq1ay3+4ly6dKl5vjAHBwf16NFDs2fPLvT3AgAArGSLgQ+wUKTB7uGHH77j1Bwmk0lvvfWW3nrrrdse4+vra1XvHAAAKAZsPfABkorxPXaAPRk/fjyXYQHgRrYe+FACRqwWBsbyAwCAonW3aUbuxs3NLgY+2ALBDgAAFK3r04kg3wh2AADAegx8KJYIdgAAwDoMfCi2GDwBAACsw8CHYoseOwAAkHcMfChW6LHDHZlMJn399deSpFOnTslkMlk1bceN599KXtrMjeDgYM2aNcumbVpr48aNMplMunTpUq7PefjhhzVkyJACq+m6fv36qVu3bgX+OrdSWO8RQCEpxHXQcXf02Nmpfv366dKlS3cMVdYKDAxUfHy8ypUrl+tz4uPjVaZMGZvVYO9WrFih0qVLF3UZBepeeI9AscfAB7tFsMuj4JGrC/X1Tk15tFBf71YcHR3l7+9v1TnWHn+v8/X1LeoSCsyVK1fk5ORk1+8RKBEY+GDXuBR7j3j44Yf16quv6vXXX5evr6/8/f01fvx4i2OOHz+u1q1by8XFRbVr19b69est9t942TQrK0v33Xef5s6da3HMgQMH5ODgoNOnT0vKeSl29+7datCggVxcXNS4cWMdOHDA4vwlS5bIx8fHYtvXX38t0w1d9bGxseratav8/Pzk4eGhJk2a6Mcff7T6M/nwww9Vq1Ytubi4qGbNmvrPf/5j3vf888+rbt26ysjIkJQdSho0aKC+fftafBbLly9XixYt5OLiojp16mjTpk23fb0LFy7omWeeUaVKleTm5qbQ0FB99tlnFsfcfJkyODhYkyZN0vPPPy9PT09VrlxZCxYssDjn7Nmz6tmzp3x8fOTr66uuXbvq1KlT5v2ZmZkaNmyYfHx8VLZsWb3++ut3XMovOTlZrq6uWrNmjcX2lStXytPTU2n/97/8N954Q9WrV5ebm5uqVKmiMWPG6OrVq+bjx48fr/r16+vDDz9USEiIeY3nm9/jp59+qsaNG8vT01P+/v7q3bu3EhMTzfuvX9KOiopS48aN5ebmphYtWujo0aMW9a1atUpNmjSRi4uLypUrp+7du5v3ZWRkaMSIEapUqZLc3d3VrFkzbdy48bafAWDXGPhg1wh295CPP/5Y7u7u2rVrl6ZOnaq33nrLHN6ysrL0xBNPyMnJSbt27dK8efP0xhtv3LYtBwcHPfPMMznW6V26dKlatmypoKCgHOekpKToscceU+3atbVv3z6NHz9eI0aMsPp9pKSkqHPnzoqKitKBAwfUqVMndenSRWfOnMl1G0uXLtXYsWP1zjvvKCYmRpMmTdKYMWP08ccfS5Jmz56t1NRUjRw5UpL05ptv6tKlS/r3v/9t0c5rr72m4cOH68CBA2revLm6dOmiCxcu3PI109PT1ahRI61evVqHDh3SSy+9pD59+mj37t13rPW9994zh+ABAwbolVdeMYeaq1evKiwsTJ6entqyZYu2bdsmDw8PderUSVeuXDGfv2TJEi1atEhbt27VxYsXtXLlytu+npeXlx577LFbfrfdunWT2//9Je7p6aklS5bo8OHDev/997Vw4ULNnDnT4pwTJ07oq6++0ooVK257H+XVq1c1ceJERUdH6+uvv9apU6fUr1+/HMe9+eabeu+997R3716VKlVKzz//vHnf6tWr1b17d3Xu3FkHDhxQVFSUmjZtat4/cOBA7dixQ8uXL9cvv/yip556Sp06ddLx48dv/8ED94KEBCklJe+PLVu4R664MWAkJSUZkoykpKQc+y5fvmwcPnzYuHz5ssX2oDe+K9SHtSIiIoyuXbuan7dp08Zo1aqVxTFNmjQx3njjDcMwDGPdunVGqVKljHPnzpn3r1mzxpBkrFy50jAMw4iLizMkGQcOHDAMwzAOHDhgmEwm4/Tp04ZhGEZmZqZRqVIlY+7cueY2bjx//vz5RtmyZS0+y7lz51q0uXjxYsPb29uizpUrVxp3+1V94IEHjA8++MD8PCgoyJg5c+Ztj7///vuNZcuWWWybOHGi0bx5c/Pz7du3G6VLlzbGjBljlCpVytiyZYt53/XPYsqUKeZtV69eNe677z7j3XffNQzDMDZs2GBIMv7666/b1vHoo48aw4cPNz9v06aNMXjwYIv38eyzz5qfZ2VlGRUqVDB/xp9++qlRo0YNIysry3xMRkaG4erqaqxbt84wDMMICAgwpk6dmqPOG38/brZy5UrDw8PDSE1NNQwj+8+Ii4uLsWbNmtueM23aNKNRo0bm5+PGjTNKly5tJCYmWhx383u82Z49ewxJxt9//20Yxv9/jj/++KP5mNWrVxuSzL9LzZs3N8LDw2/Z3unTpw1HR0eL323DMIz27dsbo0aNum0d1rjd3xNAsZSSYhjZF2Szf0axd6eccjN67O4hdevWtXgeEBBgvuQVExOjwMBAVaxY0by/efPmd2yvfv36qlWrlrlnZ9OmTUpMTNRTTz11y+NjYmJUt25d8yW53LzGraSkpGjEiBGqVauWfHx85OHhoZiYmFz32KWmpio2NlYvvPCCPDw8zI+3335bsbGxFrWNGDFCEydO1PDhw9WqVascbd1Yf6lSpdS4cWPFxMTc8nUzMzM1ceJEhYaGytfXVx4eHlq3bt1d677xezOZTPL39zd/b9HR0Tpx4oQ8PT3N78PX11fp6emKjY1VUlKS4uPj1axZsxx13knnzp1VunRpffvtt5Kkr776Sl5eXurQoYP5mM8//1wtW7aUv7+/PDw8NHr06BzvJSgoSOXLl7/ja+3bt09dunRR5cqV5enpqTZt2khSjrZu/BwCAgIkyfw5/Pzzz2rfvv0t2z948KAyMzNVvXp1i+9706ZNFt83ANgDBk/cQ24eiWgymZSVlZWvNsPDw7Vs2TKNHDlSy5YtU6dOnVS2bNk8t+fg4JDj/q8b79uSpBEjRmj9+vWaPn26qlatKldXVz355JPmS493k5KSIklauHChReCRsgeIXJeVlaVt27bJ0dFRJ06cyMvbsTBt2jS9//77mjVrlkJDQ+Xu7q4hQ4bcte47fW8pKSlq1KiRli5dmuO8uwWqO3FyctKTTz6pZcuW6emnn9ayZcvUq1cvlSqV/VfGjh07FB4ergkTJigsLEze3t5avny53nvvPYt23O8yt1VqaqrCwsIUFhampUuXqnz58jpz5ozCwsJyfC43fg7X77m8/jm4urre9jVSUlLk6Oioffv2WXy/kuTh4XGXTwIohhjRijugxw6SpFq1auns2bOKj483b9u5c+ddz+vdu7cOHTqkffv26b///a/Cw8Pv+Bq//PKL0tPTb/sa5cuX199//63UG/7iufnerG3btqlfv37q3r27QkND5e/vbzFY4G78/PxUsWJFnTx5UlWrVrV4hISEmI+bNm2ajhw5ok2bNmnt2rVavHhxjrZurP/atWvat2+fatWqdcvX3bZtm7p27apnn31W9erVU5UqVXTs2LFc130rDRs21PHjx1WhQoUc78Xb21ve3t4KCAjQrl27ctR5N+Hh4Vq7dq1+/fVX/fTTTxbf7fbt2xUUFKQ333xTjRs3VrVq1cwDZqxx5MgRXbhwQVOmTNFDDz2kmjVrWgycyK26desqKirqlvsaNGigzMxMJSYm5viMGLWNEuf6iFYPj7w//PyK+l2gABHsIEnq0KGDqlevroiICEVHR2vLli16880373pecHCwWrRooRdeeEGZmZl6/PHHb3ts7969ZTKZ1L9/fx0+fFjff/+9pk+fbnFMs2bN5Obmpn/961+KjY3VsmXLtGTJEotjqlWrZr4ZPzo6Wr1797a653HChAmaPHmyZs+erWPHjungwYNavHixZsyYISl7dO/YsWP14YcfqmXLlpoxY4YGDx6skydPWrQzZ84crVy5UkeOHFFkZKT++usvi5v6b657/fr12r59u2JiYvTyyy8rISHBqrpvFh4ernLlyqlr167asmWL4uLitHHjRr366qv67bffJEmDBw/WlClT9PXXX+vIkSMaMGBAriZNbt26tfz9/RUeHq6QkBCL3s1q1arpzJkzWr58uWJjYzV79uw7Dsi4ncqVK8vJyUkffPCBTp48qW+//VYTJ060up1x48bps88+07hx4xQTE6ODBw/q3XfflSRVr15d4eHh6tu3r1asWKG4uDjt3r1bkydP1urVhTttEZBvjGjFXRDsICn7EujKlSt1+fJlNW3aVC+++KLeeeedXJ0bHh6u6Ohode/e/Y6XxDw8PLRq1SodPHhQDRo00Jtvvmn+x/c6X19f/c///I++//5783QgN0/LMmPGDJUpU0YtWrRQly5dFBYWpoYNG1r1fl988UV9+OGHWrx4sUJDQ9WmTRstWbJEISEhSk9P17PPPqt+/fqpS5cukqSXXnpJbdu2VZ8+fZSZmWluZ8qUKZoyZYrq1aunrVu36ttvv73tBM6jR49Ww4YNFRYWpocfflj+/v75Xv3Bzc1NmzdvVuXKlfXEE0+oVq1aeuGFF5Seni4vLy9J0vDhw9WnTx9FRESoefPm8vT0tJgK5HZMJpOeeeYZRUdH5+iJffzxxzV06FANHDhQ9evX1/bt2zVmzBir6y9fvryWLFmiL7/8UrVr19aUKVNyhP3cePjhh/Xll1/q22+/Vf369dWuXTuL0caLFy9W3759NXz4cNWoUUPdunXTnj17VLlyZatfCyg2GNGKWzAZN9/QdA9KTk6Wt7e3kpKSzP8YXpeenq64uDiLebiAU6dOKSQkRAcOHFD9+vWLuhwUMf6eQKFJTc2+nCplh7P8rNGKEuNOOeVm9NgBAADYCUbFAgBQWBjRigJGsAPyIDg4+I7LcgFADqzRikLApVgAAAoDI1pRCOixAwCgsCUk5G/gg5sbI1pxSwS7XOKyG4Db4e8HWM3dnRGtKBBcir2L60sQ5Xa5KgD3nrT/uxn+5uXfAKCw0WN3F6VKlZKbm5v++OMPlS5dWg4OZGEA2QzDUFpamhITE+Xj45NjLVrYGUa0ogQg2N2FyWRSQECA4uLi8rQWJgD75+Pjw7qz9o4RrSghCHa54OTkpGrVqnE5FkAOpUuXpqfuXsCIVpQQBLtccnBwYKkgAAAjWlGsEewAALAGI1pRjDESAAAAwE4Q7AAAAOwEl2IBAPaPqUpwjyDYAQDsG1OV4B7CpVgAgH1jqhLcQ+ixAwDcO5iqBHaOYAcAuHcwVQnsHJdiAQAA7AQ9dgCA4o0RrUCuEewAAMUXI1oBq3ApFgBQfDGiFbAKPXYAgJKBEa3AXRHsAAAlAyNagbviUiwAAICdINgBAADYCYIdAACAneAeOwBAwWEOOqBQEewAAAWDOeiAQselWABAwWAOOqDQ0WMHACh4zEEHFAqCHQCg4DEHHVAouBQLAABgJwh2AAAAdoJLsQCA28vPdCVMVQIUOoIdAODWmK4EKHG4FAsAuDVbTVfCVCVAoaHHDgBwd/mZroSpSoBCQ7ADANwd05UAJQKXYgEAAOwEwQ4AAMBOcCkWAOxVfqYqkZiuBCiBCHYAYI+YqgS4J3EpFgDska2mKpGYrgQoQeixAwB7l5+pSiSmKwFKEIIdANg7pioB7hnF+lJsZmamxowZo5CQELm6uur+++/XxIkTZRiG+RjDMDR27FgFBATI1dVVHTp00PHjx4uwagAAgKJRrIPdu+++q7lz5+rf//63YmJi9O6772rq1Kn64IMPzMdMnTpVs2fP1rx587Rr1y65u7srLCxM6enpRVg5AABA4SvWl2K3b9+url276tFHH5UkBQcH67PPPtPu3bslZffWzZo1S6NHj1bXrl0lSZ988on8/Pz09ddf6+mnny6y2gEAAApbse6xa9GihaKionTs2DFJUnR0tLZu3apHHnlEkhQXF6fz58+rQ4cO5nO8vb3VrFkz7dixo0hqBgCbMIzseeTy8wBwzynWPXYjR45UcnKyatasKUdHR2VmZuqdd95ReHi4JOn8+fOSJD8/P4vz/Pz8zPtuJSMjQxkZGebnycnJBVA9AOQRc9AByKM89djFxsZq9OjReuaZZ5SYmChJWrNmjX799VebFvfFF19o6dKlWrZsmfbv36+PP/5Y06dP18cff5yvdidPnixvb2/zIzAw0EYVA4ANMAcdgDyyOtht2rRJoaGh2rVrl1asWKGUlBRJ2ZdJx40bZ9PiXnvtNY0cOVJPP/20QkND1adPHw0dOlSTJ0+WJPn7+0uSEhISLM5LSEgw77uVUaNGKSkpyfw4e/asTesGAJtJSJBSUvL+2LKFOeiAe4jVwW7kyJF6++23tX79ejk5OZm3t2vXTjt37rRpcWlpaXJwsCzR0dFRWVlZkqSQkBD5+/srKirKvD85OVm7du1S8+bNb9uus7OzvLy8LB4AUCxdn4Murw9CHXBPsfoeu4MHD2rZsmU5tleoUEF//vmnTYq6rkuXLnrnnXdUuXJlPfDAAzpw4IBmzJih559/XpJkMpk0ZMgQvf3226pWrZpCQkI0ZswYVaxYUd26dbNpLQAAAMWd1cHOx8dH8fHxCgkJsdh+4MABVapUyWaFSdIHH3ygMWPGaMCAAUpMTFTFihX18ssva+zYseZjXn/9daWmpuqll17SpUuX1KpVK61du1YuLi42rQUAAKC4Mxk3LuOQCyNGjNCuXbv05Zdfqnr16tq/f78SEhLUt29f9e3b1+b32RWG5ORkeXt7KykpicuyAIpeaqrk4ZH9c0oKy4EB9zhrcorV99hNmjRJNWvWVGBgoFJSUlS7dm21bt1aLVq00OjRo/NcNAAAAPLH6h67686cOaNDhw4pJSVFDRo0ULVq1WxdW6Ghxw6ATRlG9pQleZWaKl2fn5MeO+CeZ01OyfMExZUrV1blypXzejoA2CcmFwZQhKwOdsOGDbvldpPJJBcXF1WtWlVdu3aVr69vvosDgBKHyYUBFCGrL8W2bdtW+/fvV2ZmpmrUqCFJOnbsmBwdHVWzZk0dPXpUJpNJW7duVe3atQukaFvjUiwAm7lx4ENCQv4uo7q5MQ8dgIK9FHu9N27x4sXmxpOSkvTiiy+qVatW6t+/v3r37q2hQ4dq3bp1eXsHAGAPrk8SDACFxOoeu0qVKmn9+vU5euN+/fVXdezYUefOndP+/fvVsWNHm09YXFDosQNgM0xVAsDGCnS6k6SkJCUmJubY/scffyg5OVlS9iTGV65csbZpAAAA5IPVwa5r1656/vnntXLlSv3222/67bfftHLlSr3wwgvmZbx2796t6tWr27pWAAAA3IHV99jNnz9fQ4cO1dNPP61r165lN1KqlCIiIjRz5kxJUs2aNfXhhx/atlIAAADcUZ4nKE5JSdHJkyclSVWqVJHH9XtKSiDusQNgxuTCAIqZQpmg2MPDQ3Xr1s3r6QBQ/DC5MIASLk/Bbu/evfriiy905syZHIMkVqxYYZPCAKDQMbkwgBLO6mC3fPly9e3bV2FhYfrhhx/UsWNHHTt2TAkJCerevXtB1AgAhY/JhQGUQFYHu0mTJmnmzJmKjIyUp6en3n//fYWEhOjll19WQEBAQdQIAIWPyYUBlEBWT3cSGxurRx99VJLk5OSk1NRUmUwmDR06VAsWLLB5gQAAAMgdq4NdmTJl9Pfff0vKXoXi0KFDkqRLly4pLT8jyQAAAJAvVl+Kbd26tdavX6/Q0FA99dRTGjx4sH766SetX79e7du3L4gaAQAAkAtWB7t///vfSk9PlyS9+eabKl26tLZv364ePXpo9OjRNi8QAAAAuWN1sPP19TX/7ODgoJEjR9q0IAAAAOSN1cHO0dFR8fHxqlChgsX2CxcuqEKFCsrMzLRZcQBgFVusGgEAJZjVwe52K5BlZGTIyckp3wUBQJ6wagQA5D7YzZ49W5JkMpn04YcfWqwNm5mZqc2bN6tmzZq2rxAAcoNVIwAg98Fu5syZkrJ77ObNmydHR0fzPicnJwUHB2vevHm2rxAArMWqEQDuUbkOdnFxcZKktm3basWKFSpTpkyBFQUA+cKqEQDuUVbfY7dhw4aCqAMAAAD5ZHWwy8zM1JIlSxQVFaXExERlZWVZ7P/pp59sVhwAAAByz+pgN3jwYC1ZskSPPvqo6tSpIxP3oQAAABQLVge75cuX64svvlDnzp0Loh4AAADkkYO1Jzg5Oalq1aoFUQsAAADywepgN3z4cL3//vu3nagYAPLEMLJXfsjPAwDucVZfit26das2bNigNWvW6IEHHlDp0qUt9q9YscJmxQG4R7BqBADYhNXBzsfHR927dy+IWgDcq1g1AgBswupgt3jx4oKoAwCysWoEAOSZ1cFOkq5du6aNGzcqNjZWvXv3lqenp37//Xd5eXlZrCELAFZj1QgAyDOrg93p06fVqVMnnTlzRhkZGfrHP/4hT09Pvfvuu8rIyGC9WAAAgCJi9ajYwYMHq3Hjxvrrr7/k6upq3t69e3dFRUXZtDgAAADkntU9dlu2bNH27dvl5ORksT04OFjnzp2zWWEAAACwjtU9dllZWcrMzMyx/bfffpOnp6dNigIAAID1rA52HTt21KxZs8zPTSaTUlJSNG7cOJYZAwAAKEJWX4p97733FBYWptq1ays9PV29e/fW8ePHVa5cOX322WcFUSMAAABywepgd9999yk6Olqff/65oqOjlZKSohdeeEHh4eEWgykA3EMMI3uS4bxiOTAAsAmTwaKvSk5Olre3t5KSkuTl5VXU5QAli62XA0tJYR47ALiBNTnF6nvsJk+erEWLFuXYvmjRIr377rvWNgegpGM5MAAoNqwOdvPnz1fNmjVzbH/ggQeYnBi41yUkZPe45fWxZQvLgQFAPlh9j9358+cVEBCQY3v58uUVHx9vk6IAlFAsBwYARcrqHrvAwEBt27Ytx/Zt27apYsWKNikKAAAA1rO6x65///4aMmSIrl69qnbt2kmSoqKi9Prrr2v48OE2LxAAAAC5Y3Wwe+2113ThwgUNGDBAV65ckSS5uLjojTfe0KhRo2xeIAAAAHLHqulOMjMztW3bNoWGhqp06dKKiYmRq6urqlWrJmdn54Kss0Ax3QmQD6mpkodH9s9MVQIANmdNTrGqx87R0VEdO3ZUTEyMQkJC1KRJk3wVCgAAANuxevBEnTp1dPLkyYKoBQAAAPlg9T12b7/9tkaMGKGJEyeqUaNGcr/psguXMoEShuXAAMBuWL2kmIPD/3fymW6YSNQwDJlMJmVmZtquukLCPXa4Z7EcGAAUewV2j50kbdiwIc+FAShmWA4MAOyK1cGuTZs2BVEHgKKWkJC/3jY3N5YDA4AiZvXgCUnasmWLnn32WbVo0ULnzp2TJH366afaunWrTYsDUIiuLweW1wehDgCKnNXB7quvvlJYWJhcXV21f/9+ZWRkSJKSkpI0adIkmxcIAACA3LE62L399tuaN2+eFi5cqNKlS5u3t2zZUvv377dpcQAAAMg9q4Pd0aNH1bp16xzbvb29denSJVvUBAAAgDywOtj5+/vrxIkTObZv3bpVVapUsUlRAAAAsJ7Vwa5///4aPHiwdu3aJZPJpN9//11Lly7ViBEj9MorrxREjQAAAMgFq6c7GTlypLKystS+fXulpaWpdevWcnZ21ogRIzRo0KCCqBEAAAC5YPXKE9dduXJFJ06cUEpKimrXri0PDw9b11ZoWHkC96zUVOn6n11WjQCAYqlAV564zsnJSZ6envL09CzRoQ4o0VjnFQBwA6vvsbt27ZrGjBkjb29vBQcHKzg4WN7e3ho9erSuXr1aEDUCuJXr67x6eOT94edX1O8CAGBDVvfYDRo0SCtWrNDUqVPVvHlzSdKOHTs0fvx4XbhwQXPnzrV5kQBugXVeAQA3sbrHbtmyZVqyZIlefvll1a1bV3Xr1tXLL7+sjz76SMuWLbN5gefOndOzzz6rsmXLytXVVaGhodq7d695v2EYGjt2rAICAuTq6qoOHTro+PHjNq8DKNYSErLvkcvrY8sWlgQDADtgdY+ds7OzgoODc2wPCQmRk5OTLWoy++uvv9SyZUu1bdtWa9asUfny5XX8+HGVKVPGfMzUqVM1e/ZsffzxxwoJCdGYMWMUFhamw4cPy8XFxab1AMXW9fVaAQD3NKtHxb711ls6cuSIFi9eLGdnZ0lSRkaGXnjhBVWrVk3jxo2zWXEjR47Utm3btGXLllvuNwxDFStW1PDhwzVixAhJ2WvW+vn5acmSJXr66adz9TqMikWJxIhWALgnFOio2AMHDigqKkr33Xef6tWrJ0mKjo7WlStX1L59ez3xxBPmY1esWGFt8xa+/fZbhYWF6amnntKmTZtUqVIlDRgwQP3795ckxcXF6fz58+rQoYP5HG9vbzVr1kw7duy4bbDLyMhQRkaG+XlycnK+6gQAACgOrA52Pj4+6tGjh8W2wMBAmxV0o5MnT2ru3LkaNmyY/vWvf2nPnj169dVX5eTkpIiICJ0/f16S5HfTyD4/Pz/zvluZPHmyJkyYUCA1AwAAFBWrg93ixYsLoo5bysrKUuPGjTVp0iRJUoMGDXTo0CHNmzdPEREReW531KhRGjZsmPl5cnJygYVTAACAwmL1qNjCFBAQoNq1a1tsq1Wrls6cOSNJ8vf3lyQlJCRYHJOQkGDedyvOzs7y8vKyeAAAAJR0xTrYtWzZUkePHrXYduzYMQUFBUnKHonr7++vqKgo8/7k5GTt2rXLPMceAADAvSLPS4oVhqFDh6pFixaaNGmSevbsqd27d2vBggVasGCBJMlkMmnIkCF6++23Va1aNfN0JxUrVlS3bt2KtngAAIBCVqyDXZMmTbRy5UqNGjVKb731lkJCQjRr1iyFh4ebj3n99deVmpqql156SZcuXVKrVq20du1a5rADAAD3HKvnsbtRenq6XQQo5rFDkTCM7GXB8io19f/XemUeOwCwW9bkFKvvscvKytLEiRNVqVIleXh46OTJk5KkMWPG6KOPPspbxcC9xjCkVq2yJxjO6+OmaX4AALA62L399ttasmSJpk6darGEWJ06dfThhx/atDjAbqWlSdu326atli0lNzfbtAUAKNGsvsfuk08+0YIFC9S+fXv985//NG+vV6+ejhw5YtPigHtCQkL+LqO6uUkmk+3qAQCUWFYHu3Pnzqlq1ao5tmdlZenq1as2KQq4p7i7c38cAMAmrL4UW7t2bW3ZsiXH9v/+979q0KCBTYoCAACA9azusRs7dqwiIiJ07tw5ZWVlacWKFTp69Kg++eQTfffddwVRIwAAAHLB6h67rl27atWqVfrxxx/l7u6usWPHKiYmRqtWrdI//vGPgqgRAAAAuZCnCYofeughrV+/3ta1AAAAIB+s7rHbs2ePdu3alWP7rl27tHfvXpsUBQAAAOtZHewiIyN19uzZHNvPnTunyMhImxQFAAAA61kd7A4fPqyGDRvm2N6gQQMdPnzYJkUBAADAelYHO2dnZyUkJOTYHh8fr1Kl8nTLHgAAAGzA6iTWsWNHjRo1St988428vb0lSZcuXdK//vUvRsXi3mIY2UuD5UVqqm1rAQBAeQh206dPV+vWrRUUFGSekPjnn3+Wn5+fPv30U5sXCBRLhiG1amW79V4BALABq4NdpUqV9Msvv2jp0qWKjo6Wq6urnnvuOT3zzDMqXbp0QdQIFD9pabYJdS1bZq/1CgCADeTppjh3d3e99NJLtq4FKJkSEvK+1qubm2Qy2bYeAMA9K0/B7vjx49qwYYMSExOVlZVlsW/s2LE2KQwoMdzd8x7sAACwIauD3cKFC/XKK6+oXLly8vf3l+mG3gaTyUSwAwAAKCJWB7u3335b77zzjt54442CqAcAAAB5ZPU8dn/99ZeeeuqpgqgFAAAA+WB1sHvqqaf0ww8/FEQtAAAAyAerL8VWrVpVY8aM0c6dOxUaGppjipNXX33VZsUBAAAg90yGYRjWnBASEnL7xkwmnTx5Mt9FFbbk5GR5e3srKSlJXl5eRV0OSoLUVMnDI/vnlBRGxQIACow1OcXqHru4uLg8FwYAAICCY/U9dgAAACie8jRB8W+//aZvv/1WZ86c0ZUrVyz2zZgxwyaFAQAAwDpWB7uoqCg9/vjjqlKlio4cOaI6dero1KlTMgxDDRs2LIgaAQAAkAtWB7tRo0ZpxIgRmjBhgjw9PfXVV1+pQoUKCg8PV6dOnQqiRsD2DENKS8v7+amptqsFAAAbsTrYxcTE6LPPPss+uVQpXb58WR4eHnrrrbfUtWtXvfLKKzYvErApw5BatZK2by/qSgAAsCmrB0+4u7ub76sLCAhQbGysed+ff/5pu8qAgpKWZrtQ17Kl5OZmm7YAAMgnq3vsHnzwQW3dulW1atVS586dNXz4cB08eFArVqzQgw8+WBA1AgUnISF/c9C5uUkmk+3qAQAgH6wOdjNmzFBKSookacKECUpJSdHnn3+uatWqMSIWJY+7O5MLAwDshtUrT9gjVp64x7BqBACgBLEmpzBBMQAAgJ3I1aVYX19fHTt2TOXKlVOZMmVkusM9RRcvXrRZcQAAAMi9XAW7mTNnytPTU5I0a9asgqwHAAAAeZSrYBcRESFJunbtmkwmk8LCwuTn51eghQEAAMA6Vt1jV6pUKf3zn/9Uenp6QdUDAACAPLJ68ETTpk114MCBgqgFAAAA+WD1PHYDBgzQ8OHD9dtvv6lRo0Zyv2mqiLp169qsOAAAAOSe1fPYOTjk7OQzmUwyDEMmk0mZmZk2K66wMI/dPYZ57AAAJYg1OcXqHru4uLg8FwYAAICCY3WwCwoKKog6gNwzDCktLe/np6barhYAAIoRq4PddYcPH9aZM2d05coVi+2PP/54vosCbsswpFatpO3bi7oSAACKHauD3cmTJ9W9e3cdPHjQfG+dJPNqFCXxHjuUIGlptgt1LVtKbm62aQsAgGLA6ulOBg8erJCQECUmJsrNzU2//vqrNm/erMaNG2vjxo0FUCJwGwkJ2YMf8vrYskW6w/J4AACUNFb32O3YsUM//fSTypUrJwcHBzk4OKhVq1aaPHmyXn31Vea4Q+Fxd2dEKwAAN7C6xy4zM9O8bmy5cuX0+++/S8oeVHH06FHbVgcAAIBcs7rHrk6dOoqOjlZISIiaNWumqVOnysnJSQsWLFCVKlUKokYAAADkgtXBbvTo0Ur9v+ki3nrrLT322GN66KGHVLZsWX3++ec2LxAAAAC5Y3WwCwsLM/9ctWpVHTlyRBcvXlSZMmXMI2MBAABQ+Ky+x+5//ud/zD121/n6+hLqAAAAipjVwW7o0KHy8/NT79699f333zNvHQAAQDFhdbCLj4/X8uXLZTKZ1LNnTwUEBCgyMlLbWQkAAACgSFkd7EqVKqXHHntMS5cuVWJiombOnKlTp06pbdu2uv/++wuiRgAAAORCnteKlSQ3NzeFhYXpr7/+0unTpxUTE2OrugAAAGAlq3vsJCktLU1Lly5V586dValSJc2aNUvdu3fXr7/+auv6AAAAkEtW99g9/fTT+u677+Tm5qaePXtqzJgxat68eUHUBgAAACtYHewcHR31xRdfKCwsTI6OjgVREwAAAPLA6mC3dOnSgqgD9wrDkNLS8n7+TXMoAgCA/5evwROAVQxDatVKYmocAAAKRJ4GTwB5kpZmu1DXsqXk5mabtgAAsBP02KFoJCRI7u55P9/NTWIZOwAALBDsUDTc3fMX7AAAQA65CnbJycm5btDLyyvPxQAAACDvchXsfHx8ZMrlZa/MzMx8FQQAAIC8ydXgiQ0bNuinn37STz/9pEWLFqlChQp6/fXXtXLlSq1cuVKvv/66/Pz8tGjRogItdsqUKTKZTBoyZIh5W3p6uiIjI1W2bFl5eHioR48eSkhIKNA6AAAAiiOTYRiGNSe0b99eL774op555hmL7cuWLdOCBQu0ceNGW9ZntmfPHvXs2VNeXl5q27atZs2aJUl65ZVXtHr1ai1ZskTe3t4aOHCgHBwctG3btly3nZycLG9vbyUlJXEpuSClpkoeHtk/p6Rwjx0AALlgTU6xerqTHTt2qHHjxjm2N27cWLt377a2uVxJSUlReHi4Fi5cqDJlypi3JyUl6aOPPtKMGTPUrl07NWrUSIsXL9b27du1c+fOAqkFAACguLI62AUGBmrhwoU5tn/44YcKDAy0SVE3i4yM1KOPPqoOHTpYbN+3b5+uXr1qsb1mzZqqXLmyduzYUSC1AAAAFFdWT3cyc+ZM9ejRQ2vWrFGzZs0kSbt379bx48f11Vdf2bzA5cuXa//+/dqzZ0+OfefPn5eTk5N8fHwstvv5+en8+fO3bTMjI0MZGRnm59aM+gUAACiurO6x69y5s44dO6YuXbro4sWLunjxorp06aJjx46pc+fONi3u7NmzGjx4sJYuXSoXFxebtTt58mR5e3ubHwXV0wgAAFCYrB48UZi+/vprde/eXY6OjuZtmZmZMplMcnBw0Lp169ShQwf99ddfFr12QUFBGjJkiIYOHXrLdm/VYxcYGMjgiYLG4AkAAKxWoIMnJGnLli169tln1aJFC507d06S9Omnn2rr1q15ae622rdvr4MHD+rnn382Pxo3bqzw8HDzz6VLl1ZUVJT5nKNHj+rMmTNq3rz5bdt1dnaWl5eXxQMAAKCks/oeu6+++kp9+vRReHi49u/fb+75SkpK0qRJk/T999/brDhPT0/VqVPHYpu7u7vKli1r3v7CCy9o2LBh8vX1lZeXlwYNGqTmzZvrwQcftFkdAAAAJYHVPXZvv/225s2bp4ULF6p06dLm7S1bttT+/fttWlxuzJw5U4899ph69Oih1q1by9/fXytWrCj0OgAAAIqa1ffYubm56fDhwwoODpanp6eio6NVpUoVnTx5UrVr11Z6enpB1VpgmKC4kHCPHQAAVrMmp1h9Kdbf318nTpxQcHCwxfatW7eqSpUq1jaHksQwpLS0vJ+fmmq7WgAAQA5WB7v+/ftr8ODBWrRokUwmk37//Xft2LFDI0aM0JgxYwqiRhQHhiG1aiVt317UlQAAgNuwOtiNHDlSWVlZat++vdLS0tS6dWs5OztrxIgRGjRoUEHUiOIgLc12oa5lS8nNzTZtAQAAszzPY3flyhWdOHFCKSkpql27tjyu3ztVAnGPXS7ceH9cQkL+7o9zc5NMJtvUBQCAnSvQe+yuc3JyUu3atfN6Okoyd3cGPgAAUAxZHexSU1M1ZcoURUVFKTExUVlZWRb7T548abPiAAAAkHtWB7sXX3xRmzZtUp8+fRQQECATl9QAAACKBauD3Zo1a7R69Wq1bNmyIOoBAABAHlm98kSZMmXk6+tbELUAAAAgH6wOdhMnTtTYsWOVlp+JagEAAGBzVl+Kfe+99xQbGys/Pz8FBwdbrBcrqUjWiwUAAEAegl23bt0KoAwAAADkl9XBbty4cQVRBwAAAPLJ6nvsAAAAUDzlqsfO19dXx44dU7ly5VSmTJk7zl138eJFmxUHAACA3MtVsJs5c6Y8PT0lSbNmzSrIegAAAJBHJsMwjKIuoqhZs7juPSs1VfLwyP45JYW1YgEAKCTW5BSrB0/cKD09XVeuXLHYRjACAAAoGlYPnkhNTdXAgQNVoUIFubu7q0yZMhYPAAAAFA2rg93rr7+un376SXPnzpWzs7M+/PBDTZgwQRUrVtQnn3xSEDUCAAAgF6y+FLtq1Sp98sknevjhh/Xcc8/poYceUtWqVRUUFKSlS5cqPDy8IOoEAADAXVgd7C5evKgqVapIyr6f7vr0Jq1atdIrr7xi2+pgO4Yh5Wd939RU29UCAAAKhNXBrkqVKoqLi1PlypVVs2ZNffHFF2ratKlWrVolHx+fAigR+WYYUqtW0vbtRV0JAAAoQFbfY/fcc88pOjpakjRy5EjNmTNHLi4uGjp0qF577TWbFwgbSEuzXahr2VJyc7NNWwAAwKbyPY/d6dOntW/fPlWtWlV169a1VV2Fyu7nsbtxDrqEhPzNQefmJt1h5REAAGBbhTaPnSQFBQUpKCgov82gsLi7M7kwAAB2KlfBbvbs2blu8NVXX81zMQAAAMi7XF2KDQkJyV1jJpNOnjyZ76IK2z11KZblwAAAKFFsfik2Li7OJoUBAACg4Fg9KvZGhmEon2MvAAAAYCN5CnYfffSR6tSpIxcXF7m4uKhOnTr68MMPbV0bAAAArGD1qNixY8dqxowZGjRokJo3by5J2rFjh4YOHaozZ87orbfesnmRAAAAuDur57ErX768Zs+erWeeecZi+2effaZBgwbpzz//tGmBhYHBEwAAoLiyJqdYfSn26tWraty4cY7tjRo10rVr16xtDgAAADZidbDr06eP5s6dm2P7ggULFB4ebpOiAAAAYL08rTzx0Ucf6YcfftCDDz4oSdq1a5fOnDmjvn37atiwYebjZsyYYZsqAQAAcFdWB7tDhw6pYcOGkqTY2FhJUrly5VSuXDkdOnTIfJyJ9UQBAAAKldXBbsOGDQVRBwAAAPLJ6nvs/vjjj9vuO3jwYL6KAQAAQN5ZHexCQ0O1evXqHNunT5+upk2b2qQoAAAAWM/qYDds2DD16NFDr7zyii5fvqxz586pffv2mjp1qpYtW1YQNQIAACAXrA52r7/+unbs2KEtW7aobt26qlu3rpydnfXLL7+oe/fuBVEjAAAAciFPa8VWrVpVderU0alTp5ScnKxevXrJ39/f1rUBAADAClYHu23btqlu3bo6fvy4fvnlF82dO1eDBg1Sr1699NdffxVEjQAAAMgFq4Ndu3bt1KtXL+3cuVO1atXSiy++qAMHDujMmTMKDQ0tiBoBAACQC1bPY/fDDz+oTZs2Ftvuv/9+bdu2Te+8847NCgMAAIB1TIZhGEVdRFFLTk6Wt7e3kpKS5OXlVdTl2F5qquThkf1zSork7l609QAAgFyzJqfk+lJs586dlZSUZH4+ZcoUXbp0yfz8woULql27tvXV4u4MIzuc5ecBAADsXq577BwdHRUfH68KFSpIkry8vPTzzz+rSpUqkqSEhARVrFhRmZmZBVdtASnWPXaGIbVqJW3fbpv26LEDAKBEKZAeu5vzH1dwC0lamu1CXcuWkpubbdoCAADFjtWDJ1CEEhLy19vm5iaZTLarBwAAFCu5DnYmk0mmm0LBzc9RwNzduYwKAABuK9fBzjAM9evXT87OzpKk9PR0/fOf/5T7/wWNjIyMgqkQAAAAuZLrYBcREWHx/Nlnn81xTN++ffNfEQAAAPIk18Fu8eLFBVkHAAAA8snqJcUAAABQPBHsAAAA7ATBDgAAwE4Q7AAAAOwEwQ4AAMBOEOwAAADsBMEOAADAThDsAAAA7ATBDgAAwE4Q7AAAAOwEwQ4AAMBOEOwAAADsRLEOdpMnT1aTJk3k6empChUqqFu3bjp69KjFMenp6YqMjFTZsmXl4eGhHj16KCEhoYgqBgAAKDrFOtht2rRJkZGR2rlzp9avX6+rV6+qY8eOSk1NNR8zdOhQrVq1Sl9++aU2bdqk33//XU888UQRVg0AAFA0TIZhGEVdRG798ccfqlChgjZt2qTWrVsrKSlJ5cuX17Jly/Tkk09Kko4cOaJatWppx44devDBB3PVbnJysry9vZWUlCQvL6+CfAvWS02VPDyyf05Jkdzdi7YeAABQqKzJKcW6x+5mSUlJkiRfX19J0r59+3T16lV16NDBfEzNmjVVuXJl7dix47btZGRkKDk52eIBAABQ0pWYYJeVlaUhQ4aoZcuWqlOnjiTp/PnzcnJyko+Pj8Wxfn5+On/+/G3bmjx5sry9vc2PwMDAgiwdAACgUJSYYBcZGalDhw5p+fLl+W5r1KhRSkpKMj/Onj1rgwoBAACKVqmiLiA3Bg4cqO+++06bN2/WfffdZ97u7++vK1eu6NKlSxa9dgkJCfL3979te87OznJ2di7IkgEAAApdse6xMwxDAwcO1MqVK/XTTz8pJCTEYn+jRo1UunRpRUVFmbcdPXpUZ86cUfPmzQu7XAAAgCJVrHvsIiMjtWzZMn3zzTfy9PQ03zfn7e0tV1dXeXt764UXXtCwYcPk6+srLy8vDRo0SM2bN8/1iFgAAAB7UayD3dy5cyVJDz/8sMX2xYsXq1+/fpKkmTNnysHBQT169FBGRobCwsL0n//8p5ArBQAAKHolah67gsI8dgAAoLiy23nsAAAAcHsEOwAAADtBsAMAALATBDsAAAA7QbADAACwEwQ7AAAAO0GwAwAAsBPFeoLie4JhSGlpt9+fmlp4tQAAgBKNYFfU0tL+fwJiAACAfCDYFaLgkatzbHO9kq6Y3JzcsqXk5mbzmgAAgP0g2BWxy6WdVWvof2+7P2Zip+wf3Nwkk6mQqgIAACURwa6omUy67ORy+/2sDQsAAHKJUbEAAAB2gmAHAABgJwh2AAAAdoJgBwAAYCcIdgAAAHaCYAcAAGAnCHYAAAB2gmAHAABgJwh2AAAAdoJgBwAAYCcIdgAAAHaCYAcAAGAnCHYAAAB2gmAHAABgJwh2AAAAdoJgBwAAYCcIdgAAAHaCYAcAAGAnCHYAAAB2gmAHAABgJwh2AAAAdqJUURcA6wSPXG31OaemPFoAlQAAgOKGHjsAAAA7QbADAACwEwQ7AAAAO0GwAwAAsBMEOwAAADtBsAMAALATBDsAAAA7QbADAACwEwQ7AAAAO0GwAwAAsBMsKXYPYlkyAADsEz12AAAAdoJgBwAAYCcIdgAAAHaCYAcAAGAnCHYAAAB2glGxyBNG1gIAUPzQYwcAAGAn6LFDkchLj59Erx8AAHdCjx0AAICdoMcOJRa9fgAAWCLY4Z5GOAQA2BMuxQIAANgJeuyAfLJFr19xaQMAULLRYwcAAGAn6LEDYMbE0wBQshHsANiULcIhARMA8oZgB8AuFZeASUgFUJgIdgBQjDEoBoA1CHYAYOcYdQ3cOwh2AIBCUVwCZlG1QchFYSDYAQBQBIrLPZyEVPtiN8Fuzpw5mjZtms6fP6969erpgw8+UNOmTYu6LAAA7F5+w2Fx6Ym1B3YxQfHnn3+uYcOGady4cdq/f7/q1aunsLAwJSYmFnVpAAAAhcYugt2MGTPUv39/Pffcc6pdu7bmzZsnNzc3LVq0qKhLAwAAKDQl/lLslStXtG/fPo0aNcq8zcHBQR06dNCOHTuKsDIAAFCS2MPl3BIf7P78809lZmbKz8/PYrufn5+OHDlyy3MyMjKUkZFhfp6UlCRJSk5OLrhCJWVlpFl9zs012UsbeTmfNopnG8Xx98ue2ijJvxu0cfvzaaN4fCcF0UZBuN6+YRh3P9go4c6dO2dIMrZv326x/bXXXjOaNm16y3PGjRtnSOLBgwcPHjx48Cgxj7Nnz941F5X4Hrty5crJ0dFRCQkJFtsTEhLk7+9/y3NGjRqlYcOGmZ9nZWXp4sWLKlu2rEwmU4HWeyvJyckKDAzU2bNn5eXlVWRtAACA4scwDP3999+qWLHiXY8t8cHOyclJjRo1UlRUlLp16yYpO6hFRUVp4MCBtzzH2dlZzs7OFtt8fHwKuNK78/Lyyncos0UbAACgePH29s7VcSU+2EnSsGHDFBERocaNG6tp06aaNWuWUlNT9dxzzxV1aQAAAIXGLoJdr1699Mcff2js2LE6f/686tevr7Vr1+YYUAEAAGDP7CLYSdLAgQNve+m1uHN2dta4ceNyXB4u7DYAAEDJZjKM3IydBQAAQHFnFytPAAAAgGAHAABgNwh2AAAAdoJgV4Q2b96sLl26qGLFijKZTPr666+tOn/y5Mlq0qSJPD09VaFCBXXr1k1Hjx4tmGIBAECxR7ArQqmpqapXr57mzJmTp/M3bdqkyMhI7dy5U+vXr9fVq1fVsWNHpaam2rhSAABQEjAqtpgwmUxauXKlefWMvPjjjz9UoUIFbdq0Sa1bt7ZdcQAAoESgx86OJCUlSZJ8fX2LuBIAAFAUCHZ2IisrS0OGDFHLli1Vp06doi4HAAAUAbtZeeJeFxkZqUOHDmnr1q1FXQoAACgiBDs7MHDgQH333XfavHmz7rvvvqIuBwAAFBGCXQlmGIYGDRqklStXauPGjQoJCSnqkgAAQBEi2BWhlJQUnThxwvw8Li5OP//8s3x9fVW5cuW7nh8ZGally5bpm2++kaenp86fPy9J8vb2lqura4HVDQAAiiemOylCGzduVNu2bXNsj4iI0JIlS+56vslkuuX2xYsXq1+/fvmsDgAAlDQEOwAAADvBdCcAAAB2gmAHAABgJwh2AAAAdoJgBwAAYCcIdgAAAHaCYAcAAGAnCHYAAAB2gmAHAABgJwh2AFACPfzwwxoyZEi+2jh16pRMJpN+/vlnm9QEoOgR7AAUivPnz2vQoEGqUqWKnJ2dFRgYqC5duigqKqqoSytW+vXrp27dut31uBUrVmjixIkFXxCAEqVUURcAwP6dOnVKLVu2lI+Pj6ZNm6bQ0FBdvXpV69atU2RkpI4cOVLUJZY4vr6+RV0CgGKIHjsABW7AgAEymUzavXu3evTooerVq+uBBx7QsGHDtHPnTvNxZ86cUdeuXeXh4SEvLy/17NlTCQkJ5v3jx49X/fr1tWjRIlWuXFkeHh4aMGCAMjMzNXXqVPn7+6tChQp65513LF7fZDJp7ty5euSRR+Tq6qoqVarov//9r8UxBw8eVLt27eTq6qqyZcvqpZdeUkpKinn/9Z606dOnKyAgQGXLllVkZKSuXr1qPiYjI0MjRoxQpUqV5O7urmbNmmnjxo3m/UuWLJGPj4/WrVunWrVqycPDQ506dVJ8fLz5/X388cf65ptvZDKZZDKZLM6/0c2XYoODgzVp0iQ9//zz8vT0VOXKlbVgwQKLc3bv3q0GDRrIxcVFjRs31oEDB3K0e+jQIT3yyCPy8PCQn5+f+vTpoz///FOStHHjRjk5OWnLli3m46dOnaoKFSpYfE8AipABAAXowoULhslkMiZNmnTH4zIzM4369esbrVq1Mvbu3Wvs3LnTaNSokdGmTRvzMePGjTM8PDyMJ5980vj111+Nb7/91nBycjLCwsKMQYMGGUeOHDEWLVpkSDJ27txpPk+SUbZsWWPhwoXG0aNHjdGjRxuOjo7G4cOHDcMwjJSUFCMgIMB44oknjIMHDxpRUVFGSEiIERERYW4jIiLC8PLyMv75z38aMTExxqpVqww3NzdjwYIF5mNefPFFo0WLFsbmzZuNEydOGNOmTTOcnZ2NY8eOGYZhGIsXLzZKly5tdOjQwdizZ4+xb98+o1atWkbv3r0NwzCMv//+2+jZs6fRqVMnIz4+3oiPjzcyMjJu+Xm1adPGGDx4sPl5UFCQ4evra8yZM8c4fvy4MXnyZMPBwcE4cuSIue3y5csbvXv3Ng4dOmSsWrXKqFKliiHJOHDggGEYhvHXX38Z5cuXN0aNGmXExMQY+/fvN/7xj38Ybdu2Nb/Oa6+9ZgQFBRmXLl0y9u/fbzg5ORnffPPNHb9bAIWHYAegQO3atcuQZKxYseKOx/3www+Go6OjcebMGfO2X3/91ZBk7N692zCM7GDn5uZmJCcnm48JCwszgoODjczMTPO2GjVqGJMnTzY/l2T885//tHi9Zs2aGa+88ophGIaxYMECo0yZMkZKSop5/+rVqw0HBwfj/PnzhmFkB7ugoCDj2rVr5mOeeuopo1evXoZhGMbp06cNR0dH49y5cxav0759e2PUqFGGYWQHO0nGiRMnzPvnzJlj+Pn5mZ9HREQYXbt2veNnZRi3DnbPPvus+XlWVpZRoUIFY+7cuYZhGMb8+fONsmXLGpcvXzYfM3fuXItgN3HiRKNjx44Wr3P27FlDknH06FHDMAwjIyPDqF+/vtGzZ0+jdu3aRv/+/e9aK4DCwz12AAqUYRi5Oi4mJkaBgYEKDAw0b6tdu7Z8fHwUExOjJk2aSMq+5Ojp6Wk+xs/PT46OjnJwcLDYlpiYaNF+8+bNczy/Pho0JiZG9erVk7u7u3l/y5YtlZWVpaNHj8rPz0+S9MADD8jR0dF8TEBAgA4ePCgp+1JuZmamqlevbvE6GRkZKlu2rPm5m5ub7r//fos2bq41r+rWrWv+2WQyyd/f39x2TEyM6tatKxcXF/MxN38m0dHR2rBhgzw8PHK0HRsbq+rVq8vJyUlLly5V3bp1FRQUpJkzZ9qkdgC2QbADUKCqVasmk8lkswESpUuXtnhuMpluuS0rK8smr3e3177+OikpKXJ0dNS+ffsswp8ki6B0qzZyG37zU19upKSkqEuXLnr33Xdz7AsICDD/vH37dknSxYsXdfHiRYtADKBoMXgCQIHy9fVVWFiY5syZo9TU1Bz7L126JEmqVauWzp49q7Nnz5r3HT58WJcuXVLt2rXzXceNgzSuP69Vq5b5taOjoy3q27ZtmxwcHFSjRo1ctd+gQQNlZmYqMTFRVatWtXj4+/vnuk4nJydlZmbm+vjcqlWrln755Relp6ebt938mTRs2FC//vqrgoODc7yH6+EtNjZWQ4cO1cKFC9WsWTNFREQUSIgGkDcEOwAFbs6cOcrMzFTTpk311Vdf6fjx44qJidHs2bPNlwM7dOig0NBQhYeHa//+/dq9e7f69u2rNm3aqHHjxvmu4csvv9SiRYt07NgxjRs3Trt379bAgQMlSeHh4XJxcVFERIQOHTqkDRs2aNCgQerTp4/5MuzdVK9eXeHh4erbt69WrFihuLg47d69W5MnT9bq1atzXWdwcLB++eUXHT16VH/++afFqNv86N27t0wmk/r376/Dhw/r+++/1/Tp0y2OiYyM1MWLF/XMM89oz549io2N1bp16/Tcc88pMzNTmZmZevbZZxUWFqbnnntOixcv1i+//KL33nvPJjUCyD+CHYACV6VKFe3fv19t27bV8OHDVadOHf3jH/9QVFSU5s6dKyn7suE333yjMmXKqHXr1urQoYOqVKmizz//3CY1TJgwQcuXL1fdunX1ySef6LPPPjP3BLq5uWndunW6ePGimjRpoieffFLt27fXv//9b6teY/Hixerbt6+GDx+uGjVqqFu3btqzZ48qV66c6zb69++vGjVqqHHjxipfvry2bdtmVQ234+HhoVWrVungwYNq0KCB3nzzzRyXXCtWrKht27YpMzNTHTt2VGhoqIYMGSIfHx85ODjonXfe0enTpzV//nxJ2ZdnFyxYoNGjRys6OtomdQLIH5Nhq5s7AKCYMplMWrlyZa5WdACAkoweOwAAADtBsAMAALATTHcCwO5xxwmAewU9dgAAAHaCYAcAAGAnCHYAAAB2gmAHAABgJwh2AAAAdoJgBwAAYCcIdgAAAHaCYAcAAGAnCHYAAAB24n8BmDS3n6u/T4wAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "exp_var = lda.explained_variance_ratio_ * 100\n",
    "cum_exp_var = np.cumsum(exp_var)\n",
    "\n",
    "plt.bar(range(1, 31), exp_var, align='center',\n",
    "        label='Individual explained variance')\n",
    "\n",
    "plt.step(range(1, 31), cum_exp_var, where='mid',\n",
    "         label='Cumulative explained variance', color='red')\n",
    "\n",
    "plt.ylabel('Explained variance percentage')\n",
    "plt.xlabel('Component index')\n",
    "plt.xticks(ticks=[1, 2])\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"Barplot_LDA.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'c' argument must be a color, a sequence of colors, or a sequence of numbers, not                                        Secteur\n0          Produits laitiers et desserts frais\n1          Produits laitiers et desserts frais\n2          Produits laitiers et desserts frais\n3          Produits laitiers et desserts frais\n4          Produits laitiers et desserts frais\n...                                        ...\n65231  Sirops et boissons concentrees a diluer\n65232  Sirops et boissons concentrees a diluer\n65233  Sirops et boissons concentrees a diluer\n65234  Sirops et boissons concentrees a diluer\n65235  Sirops et boissons concentrees a diluer\n\n[65236 rows x 1 columns]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Thomas Aujoux\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\axes\\_axes.py:4439\u001b[0m, in \u001b[0;36mAxes._parse_scatter_color_args\u001b[1;34m(c, edgecolors, kwargs, xsize, get_next_color_func)\u001b[0m\n\u001b[0;32m   4438\u001b[0m \u001b[39mtry\u001b[39;00m:  \u001b[39m# Is 'c' acceptable as PathCollection facecolors?\u001b[39;00m\n\u001b[1;32m-> 4439\u001b[0m     colors \u001b[39m=\u001b[39m mcolors\u001b[39m.\u001b[39;49mto_rgba_array(c)\n\u001b[0;32m   4440\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\Thomas Aujoux\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\colors.py:487\u001b[0m, in \u001b[0;36mto_rgba_array\u001b[1;34m(c, alpha)\u001b[0m\n\u001b[0;32m    486\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 487\u001b[0m     rgba \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([to_rgba(cc) \u001b[39mfor\u001b[39;49;00m cc \u001b[39min\u001b[39;49;00m c])\n\u001b[0;32m    489\u001b[0m \u001b[39mif\u001b[39;00m alpha \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Thomas Aujoux\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\colors.py:487\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    486\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 487\u001b[0m     rgba \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([to_rgba(cc) \u001b[39mfor\u001b[39;00m cc \u001b[39min\u001b[39;00m c])\n\u001b[0;32m    489\u001b[0m \u001b[39mif\u001b[39;00m alpha \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Thomas Aujoux\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\colors.py:299\u001b[0m, in \u001b[0;36mto_rgba\u001b[1;34m(c, alpha)\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[39mif\u001b[39;00m rgba \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39m# Suppress exception chaining of cache lookup failure.\u001b[39;00m\n\u001b[1;32m--> 299\u001b[0m     rgba \u001b[39m=\u001b[39m _to_rgba_no_colorcycle(c, alpha)\n\u001b[0;32m    300\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Thomas Aujoux\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\colors.py:374\u001b[0m, in \u001b[0;36m_to_rgba_no_colorcycle\u001b[1;34m(c, alpha)\u001b[0m\n\u001b[0;32m    373\u001b[0m         \u001b[39mreturn\u001b[39;00m c, c, c, alpha \u001b[39mif\u001b[39;00m alpha \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m1.\u001b[39m\n\u001b[1;32m--> 374\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid RGBA argument: \u001b[39m\u001b[39m{\u001b[39;00morig_c\u001b[39m!r}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    375\u001b[0m \u001b[39m# turn 2-D array into 1-D array\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid RGBA argument: 'Secteur'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m      2\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m[\u001b[39m7\u001b[39m, \u001b[39m5\u001b[39m])\n\u001b[1;32m----> 4\u001b[0m plt\u001b[39m.\u001b[39;49mscatter(X_lda[:, \u001b[39m0\u001b[39;49m], X_lda[:, \u001b[39m1\u001b[39;49m], c\u001b[39m=\u001b[39;49my, s\u001b[39m=\u001b[39;49m\u001b[39m25\u001b[39;49m, cmap\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mplasma\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      5\u001b[0m plt\u001b[39m.\u001b[39mtitle(\u001b[39m'\u001b[39m\u001b[39mLDA for wine data with 2 components\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m plt\u001b[39m.\u001b[39mxlabel(\u001b[39m'\u001b[39m\u001b[39mComponent 1\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Thomas Aujoux\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\pyplot.py:2862\u001b[0m, in \u001b[0;36mscatter\u001b[1;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, data, **kwargs)\u001b[0m\n\u001b[0;32m   2857\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[39m.\u001b[39mscatter)\n\u001b[0;32m   2858\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mscatter\u001b[39m(\n\u001b[0;32m   2859\u001b[0m         x, y, s\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, c\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, marker\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, cmap\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, norm\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   2860\u001b[0m         vmin\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, vmax\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, alpha\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, linewidths\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m,\n\u001b[0;32m   2861\u001b[0m         edgecolors\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, plotnonfinite\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m-> 2862\u001b[0m     __ret \u001b[39m=\u001b[39m gca()\u001b[39m.\u001b[39;49mscatter(\n\u001b[0;32m   2863\u001b[0m         x, y, s\u001b[39m=\u001b[39;49ms, c\u001b[39m=\u001b[39;49mc, marker\u001b[39m=\u001b[39;49mmarker, cmap\u001b[39m=\u001b[39;49mcmap, norm\u001b[39m=\u001b[39;49mnorm,\n\u001b[0;32m   2864\u001b[0m         vmin\u001b[39m=\u001b[39;49mvmin, vmax\u001b[39m=\u001b[39;49mvmax, alpha\u001b[39m=\u001b[39;49malpha, linewidths\u001b[39m=\u001b[39;49mlinewidths,\n\u001b[0;32m   2865\u001b[0m         edgecolors\u001b[39m=\u001b[39;49medgecolors, plotnonfinite\u001b[39m=\u001b[39;49mplotnonfinite,\n\u001b[0;32m   2866\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m({\u001b[39m\"\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m\"\u001b[39;49m: data} \u001b[39mif\u001b[39;49;00m data \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m {}), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   2867\u001b[0m     sci(__ret)\n\u001b[0;32m   2868\u001b[0m     \u001b[39mreturn\u001b[39;00m __ret\n",
      "File \u001b[1;32mc:\\Users\\Thomas Aujoux\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\__init__.py:1459\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m   1457\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(ax, \u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   1458\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1459\u001b[0m         \u001b[39mreturn\u001b[39;00m func(ax, \u001b[39m*\u001b[39;49m\u001b[39mmap\u001b[39;49m(sanitize_sequence, args), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1461\u001b[0m     bound \u001b[39m=\u001b[39m new_sig\u001b[39m.\u001b[39mbind(ax, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1462\u001b[0m     auto_label \u001b[39m=\u001b[39m (bound\u001b[39m.\u001b[39marguments\u001b[39m.\u001b[39mget(label_namer)\n\u001b[0;32m   1463\u001b[0m                   \u001b[39mor\u001b[39;00m bound\u001b[39m.\u001b[39mkwargs\u001b[39m.\u001b[39mget(label_namer))\n",
      "File \u001b[1;32mc:\\Users\\Thomas Aujoux\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\axes\\_axes.py:4602\u001b[0m, in \u001b[0;36mAxes.scatter\u001b[1;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[0;32m   4599\u001b[0m \u001b[39mif\u001b[39;00m edgecolors \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   4600\u001b[0m     orig_edgecolor \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39medgecolor\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m   4601\u001b[0m c, colors, edgecolors \u001b[39m=\u001b[39m \\\n\u001b[1;32m-> 4602\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parse_scatter_color_args(\n\u001b[0;32m   4603\u001b[0m         c, edgecolors, kwargs, x\u001b[39m.\u001b[39;49msize,\n\u001b[0;32m   4604\u001b[0m         get_next_color_func\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_patches_for_fill\u001b[39m.\u001b[39;49mget_next_color)\n\u001b[0;32m   4606\u001b[0m \u001b[39mif\u001b[39;00m plotnonfinite \u001b[39mand\u001b[39;00m colors \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   4607\u001b[0m     c \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mma\u001b[39m.\u001b[39mmasked_invalid(c)\n",
      "File \u001b[1;32mc:\\Users\\Thomas Aujoux\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\axes\\_axes.py:4448\u001b[0m, in \u001b[0;36mAxes._parse_scatter_color_args\u001b[1;34m(c, edgecolors, kwargs, xsize, get_next_color_func)\u001b[0m\n\u001b[0;32m   4445\u001b[0m             \u001b[39mraise\u001b[39;00m invalid_shape_exception(c\u001b[39m.\u001b[39msize, xsize) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   4446\u001b[0m         \u001b[39m# Both the mapping *and* the RGBA conversion failed: pretty\u001b[39;00m\n\u001b[0;32m   4447\u001b[0m         \u001b[39m# severe failure => one may appreciate a verbose feedback.\u001b[39;00m\n\u001b[1;32m-> 4448\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   4449\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mc\u001b[39m\u001b[39m'\u001b[39m\u001b[39m argument must be a color, a sequence of colors, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   4450\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mor a sequence of numbers, not \u001b[39m\u001b[39m{\u001b[39;00mc\u001b[39m!r}\u001b[39;00m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   4451\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   4452\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(colors) \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, xsize):\n\u001b[0;32m   4453\u001b[0m         \u001b[39m# NB: remember that a single color is also acceptable.\u001b[39;00m\n\u001b[0;32m   4454\u001b[0m         \u001b[39m# Besides *colors* will be an empty array if c == 'none'.\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: 'c' argument must be a color, a sequence of colors, or a sequence of numbers, not                                        Secteur\n0          Produits laitiers et desserts frais\n1          Produits laitiers et desserts frais\n2          Produits laitiers et desserts frais\n3          Produits laitiers et desserts frais\n4          Produits laitiers et desserts frais\n...                                        ...\n65231  Sirops et boissons concentrees a diluer\n65232  Sirops et boissons concentrees a diluer\n65233  Sirops et boissons concentrees a diluer\n65234  Sirops et boissons concentrees a diluer\n65235  Sirops et boissons concentrees a diluer\n\n[65236 rows x 1 columns]"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=[7, 5])\n",
    "\n",
    "plt.scatter(X_lda[:, 0], X_lda[:, 1], c=y, s=25, cmap='plasma')\n",
    "plt.title('LDA for wine data with 2 components')\n",
    "plt.xlabel('Component 1')\n",
    "plt.ylabel('Component 2')\n",
    "plt.savefig(\"LDA.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into train, test\n",
    "#df_features\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_, y, test_size=0.2, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://datascience.stackexchange.com/questions/30912/what-does-baseline-mean-in-the-context-of-machine-learning\n",
    "\n",
    "A baseline is a method that uses heuristics, simple summary statistics, randomness, or machine learning to create predictions for a dataset. You can use these predictions to measure the baseline's performance (e.g., accuracy)-- this metric will then become what you compare any other machine learning algorithm against.\n",
    "\n",
    "\n",
    "A baseline is a method that uses heuristics, simple summary statistics, randomness, or machine learning to create predictions for a dataset. You can use these predictions to measure the baseline's performance (e.g., accuracy)-- this metric will then become what you compare any other machine learning algorithm against.\n",
    "\n",
    "In more detail:\n",
    "\n",
    "A machine learning algorithm tries to learn a function that models the relationship between the input (feature) data and the target variable (or label). When you test it, you will typically measure performance in one way or another. For example, your algorithm may be 75% accurate. But what does this mean? You can infer this meaning by comparing with a baseline's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Multinomial Naive Bayes\n",
    "\n",
    "The sklearn's naive bayes class has a module for multinomial models. It is designed for classification with discrete features (e.g. word counts for text classification) - perfect for this problem. With text classification, it requires integer feature counts or tf-idf input.\n",
    "\n",
    "Alpha is the only parameter that I have tuned. I tried [0.01, 0.02, 0.035, 0.04, 0.1, 0.5, 1] and found that 0.035 gives the highest validation score - 0.7424."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Best estimator after running the grid search cross validation for the Multinomial Naive Bayes model\n",
    "clf_mnb = MultinomialNB(alpha=0.035, class_prior=None, fit_prior=True)\n",
    "clf_mnb = clf_mnb.fit(X_train, y_train)\n",
    "y_pred_mnb = clf_mnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Thomas Aujoux\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Thomas Aujoux\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Thomas Aujoux\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Thomas Aujoux\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Thomas Aujoux\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.231786</td>\n",
       "      <td>0.024022</td>\n",
       "      <td>0.268825</td>\n",
       "      <td>0.268719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.137863</td>\n",
       "      <td>0.021001</td>\n",
       "      <td>0.268346</td>\n",
       "      <td>0.268790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.211831</td>\n",
       "      <td>0.023003</td>\n",
       "      <td>0.268442</td>\n",
       "      <td>0.268575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.220685</td>\n",
       "      <td>0.038761</td>\n",
       "      <td>0.267701</td>\n",
       "      <td>0.268688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.154201</td>\n",
       "      <td>0.024000</td>\n",
       "      <td>0.269522</td>\n",
       "      <td>0.268281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score  train_score\n",
       "0  0.231786    0.024022    0.268825     0.268719\n",
       "1  0.137863    0.021001    0.268346     0.268790\n",
       "2  0.211831    0.023003    0.268442     0.268575\n",
       "3  0.220685    0.038761    0.267701     0.268688\n",
       "4  0.154201    0.024000    0.269522     0.268281"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "\n",
    "pipe_nb = make_pipeline(\n",
    "    MultinomialNB(alpha=0.1)\n",
    ")\n",
    "scores = cross_validate(pipe_nb, X_train, y_train, return_train_score=True)\n",
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time       0.172407\n",
       "score_time     0.021035\n",
       "test_score     0.268529\n",
       "train_score    0.268577\n",
       "dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(scores).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter 'alpha' for estimator Pipeline(steps=[('multinomialnb', MultinomialNB())]). Valid parameters are: ['memory', 'steps', 'verbose'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 10\u001b[0m\n\u001b[0;32m      5\u001b[0m pipe_nb \u001b[39m=\u001b[39m make_pipeline(\n\u001b[0;32m      6\u001b[0m     MultinomialNB()\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      9\u001b[0m random_search \u001b[39m=\u001b[39m RandomizedSearchCV(pipe_nb, param_grid, cv\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,  n_iter\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m random_search\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n",
      "File \u001b[1;32mc:\\Users\\Thomas Aujoux\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Thomas Aujoux\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1768\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1766\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1767\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1768\u001b[0m     evaluate_candidates(\n\u001b[0;32m   1769\u001b[0m         ParameterSampler(\n\u001b[0;32m   1770\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_distributions, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_iter, random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state\n\u001b[0;32m   1771\u001b[0m         )\n\u001b[0;32m   1772\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Thomas Aujoux\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[1;32m--> 821\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    823\u001b[0m         clone(base_estimator),\n\u001b[0;32m    824\u001b[0m         X,\n\u001b[0;32m    825\u001b[0m         y,\n\u001b[0;32m    826\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    827\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    828\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    829\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    830\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    831\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    832\u001b[0m     )\n\u001b[0;32m    833\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    834\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    835\u001b[0m     )\n\u001b[0;32m    836\u001b[0m )\n\u001b[0;32m    838\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Thomas Aujoux\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\Thomas Aujoux\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1076\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1077\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1078\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1083\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1085\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1088\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32mc:\\Users\\Thomas Aujoux\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Thomas Aujoux\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\Thomas Aujoux\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\Thomas Aujoux\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\Thomas Aujoux\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;49;00m func, args, kwargs \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mitems]\n",
      "File \u001b[1;32mc:\\Users\\Thomas Aujoux\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\Thomas Aujoux\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Thomas Aujoux\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:674\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    671\u001b[0m     \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m parameters\u001b[39m.\u001b[39mitems():\n\u001b[0;32m    672\u001b[0m         cloned_parameters[k] \u001b[39m=\u001b[39m clone(v, safe\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m--> 674\u001b[0m     estimator \u001b[39m=\u001b[39m estimator\u001b[39m.\u001b[39;49mset_params(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcloned_parameters)\n\u001b[0;32m    676\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m    678\u001b[0m X_train, y_train \u001b[39m=\u001b[39m _safe_split(estimator, X, y, train)\n",
      "File \u001b[1;32mc:\\Users\\Thomas Aujoux\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\pipeline.py:211\u001b[0m, in \u001b[0;36mPipeline.set_params\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mset_params\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    193\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Set the parameters of this estimator.\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \n\u001b[0;32m    195\u001b[0m \u001b[39m    Valid parameter keys can be listed with ``get_params()``. Note that\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[39m        Pipeline class instance.\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 211\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_params(\u001b[39m\"\u001b[39;49m\u001b[39msteps\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    212\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Thomas Aujoux\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\metaestimators.py:70\u001b[0m, in \u001b[0;36m_BaseComposition._set_params\u001b[1;34m(self, attr, **params)\u001b[0m\n\u001b[0;32m     67\u001b[0m                 \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_replace_estimator(attr, name, params\u001b[39m.\u001b[39mpop(name))\n\u001b[0;32m     69\u001b[0m \u001b[39m# 3. Step parameters and other initialisation arguments\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mset_params(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n\u001b[0;32m     71\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Thomas Aujoux\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:205\u001b[0m, in \u001b[0;36mBaseEstimator.set_params\u001b[1;34m(self, **params)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[39mif\u001b[39;00m key \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m valid_params:\n\u001b[0;32m    204\u001b[0m     local_valid_params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_param_names()\n\u001b[1;32m--> 205\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    206\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid parameter \u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m!r}\u001b[39;00m\u001b[39m for estimator \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    207\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mValid parameters are: \u001b[39m\u001b[39m{\u001b[39;00mlocal_valid_params\u001b[39m!r}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    208\u001b[0m     )\n\u001b[0;32m    210\u001b[0m \u001b[39mif\u001b[39;00m delim:\n\u001b[0;32m    211\u001b[0m     nested_params[key][sub_key] \u001b[39m=\u001b[39m value\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid parameter 'alpha' for estimator Pipeline(steps=[('multinomialnb', MultinomialNB())]). Valid parameters are: ['memory', 'steps', 'verbose']."
     ]
    }
   ],
   "source": [
    "param_grid_nb = {\n",
    "    'var_smoothing': (1, 0.1, 0.01, 0.001, 0.0001, 0.00001)\n",
    "}\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pipe_nb = make_pipeline(\n",
    "    MultinomialNB()\n",
    ")\n",
    "\n",
    "random_search = RandomizedSearchCV(pipe_nb, param_grid, cv=3, verbose=2,  n_iter=5)\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "GaussianNB(var_smoothing=0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Thomas Aujoux\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "param_grid_nb = {\n",
    "    'var_smoothing': [0.1]\n",
    "}\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "nbModel_grid = GridSearchCV(estimator=GaussianNB(), param_grid=param_grid_nb, verbose=2, cv=2, n_jobs=-1)\n",
    "nbModel_grid.fit(X_train, y_train)\n",
    "print(nbModel_grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9304107909258124"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbModel_grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 152    0    0    1    0    0    0    0    0   24    0    0    0    0\n",
      "     0    3    0    0    0    4    0    1    1    1    0    2    1    0\n",
      "     0    0    0]\n",
      " [   0  297    0    8    0    0    0    0    2    1    0    0    0    1\n",
      "     0    0    0    0   16    0    0    0   10    0    0    2    0    0\n",
      "     0    0    0]\n",
      " [   0    0   67    0    0    0    5    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0]\n",
      " [   0    0    1 1298    1    0    0    0    4    0    0    0    0    2\n",
      "     0    0    0    0    7    0    0    0   17    2    1    0    0    0\n",
      "     0    0    0]\n",
      " [   0    0    0    0  368    0    0    0    0    1    1    0    0    0\n",
      "     0   39    0    0    0    0    0    0    5    5    0    0    0    0\n",
      "     1    0    0]\n",
      " [   0    0    0    0    1  263    0    0    0    0    0    0    0    0\n",
      "     0    1    0    0    0    2    0    3    0    0    2    5    2    0\n",
      "     0    0    0]\n",
      " [   0    1    5    4    0    0  258    0    6    0    0    0    0    0\n",
      "     0    0    0    0    2    0    0    0    8    1    0    0    0    0\n",
      "     0    0    0]\n",
      " [   0    0    0    0    0    0    0  532    0    0    0    0    0    0\n",
      "     0    0    0    0    0    1    0    0    4    1    0    0    0    0\n",
      "     0    0    0]\n",
      " [   0    1    0    1    0    0    1    0  292    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    7    1    0    0    0    0\n",
      "     0    0    1]\n",
      " [   1    0    0    1    0    0    0    0    0  353    0    2    3    0\n",
      "     0    1    0    0    0    0    0    0    2    3    0    0    0    0\n",
      "     0    0    2]\n",
      " [   0    0    0    0    0    0    0    0    7    0  204    0    0    0\n",
      "     2    8    0    0    0    0    0    0    7    1    0    0    0    0\n",
      "     7    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0  257    2    0\n",
      "     0    1    0    0    0    0    0    0    0    3    0    0    0    0\n",
      "     0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    1    0    1   99    0\n",
      "     0    9    0    0    0    0    0    0    1    7    0    0    0    0\n",
      "     0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0  349\n",
      "     0    5    0    0    0    0    0    1    6   11    1    0    0    0\n",
      "     0    1    0]\n",
      " [   0    0    1    1    1    0    0    0    3    3    0    0    2    0\n",
      "   609    6    0    0    0    0    0    0    7    7    0    0    0    0\n",
      "     0    0    1]\n",
      " [   1    0    0    0    5    0    0    0    0    2    0    0    1    0\n",
      "     0  443    0    0    0    0    0    0    2    2    0    0    0    0\n",
      "     0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0   27    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    1    0   42    1    0    0    0    1    1    0    0    0    0\n",
      "     0    0    0]\n",
      " [   0    1    1   23    0    0    1    0    1    0    0    0    0    0\n",
      "     0    1    0    0  586    0    0    1   16    1    0    0    0    0\n",
      "     0    0    0]\n",
      " [   0    1    0    0    0    0    0    2    0    0    0    0    0    1\n",
      "     0    2    0    0    0  891    3   16   14    0    2    5   12    1\n",
      "     0    0    0]\n",
      " [   0    1    0    3    0    0    0    2    0    1    0    0    0    1\n",
      "     0    0    0    0    0    5  376   31    3    1    3    2    0    0\n",
      "     0    1    0]\n",
      " [   0    0    0    0    0    2    0    5    0    0    0    0    0    1\n",
      "     0    2    0    0    6    8   23 1158    4    0    5   19    3    1\n",
      "     0    2    0]\n",
      " [   0    0    0   14    0    0    0    0    1    0    0    0    1    0\n",
      "     0    0    0    0    0    0    0    0   90    2    1    0    0    0\n",
      "     0    0    1]\n",
      " [   0    0    0    5    0    0    0    0    2    0    2    2    0    5\n",
      "     1    3    0    2    2    0    0    0   10 1154    0    0    0    1\n",
      "     0    0    0]\n",
      " [   0    0    0   13    0    0    0    1    0    1    0    0    0    2\n",
      "     0    5    0    1   12    3    0    8   21    6  586    1    2    8\n",
      "     0    9    1]\n",
      " [   0    3    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    1    0    0    0    0    0    1    3    0    0  286    0    0\n",
      "     0    0    0]\n",
      " [   0    0    0    0    0    1    0    0    0    0    0    0    0    0\n",
      "     0    1    0    0    0    2    0    1   13    4    0    0  150    1\n",
      "     0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    1    0    1    0   10  238\n",
      "     0    0    0]\n",
      " [   0    0    0    0    4    0    0    0    0    0    0    0    0    0\n",
      "     0   28    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "   140    0    0]\n",
      " [   0    0    0    1    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    2    0    1   11    0    0   12    0    0    0\n",
      "     0  422    1]\n",
      " [   0    0    0   16    0    0    0    0    2    1    0    0    0    0\n",
      "     0    0    0    0    8    0    0    0   10    1    0    0    0    1\n",
      "     0    0  153]] : is the confusion matrix\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "got an unexpected keyword argument 'average'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mprint\u001b[39m(confusion_matrix(y_test, y_pred), \u001b[39m\"\u001b[39m\u001b[39m: is the confusion matrix\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m accuracy_score\n\u001b[1;32m----> 7\u001b[0m \u001b[39mprint\u001b[39m(accuracy_score(y_test, y_pred, average\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mweighted\u001b[39;49m\u001b[39m\"\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39m: is the accuracy score\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m precision_score\n\u001b[0;32m      9\u001b[0m \u001b[39m#print(precision_score(y_test, y_pred), \": is the precision score\")\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Thomas Aujoux\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:175\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    172\u001b[0m func_sig \u001b[39m=\u001b[39m signature(func)\n\u001b[0;32m    174\u001b[0m \u001b[39m# Map *args/**kwargs to the function signature\u001b[39;00m\n\u001b[1;32m--> 175\u001b[0m params \u001b[39m=\u001b[39m func_sig\u001b[39m.\u001b[39;49mbind(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    176\u001b[0m params\u001b[39m.\u001b[39mapply_defaults()\n\u001b[0;32m    178\u001b[0m \u001b[39m# ignore self/cls and positional/keyword markers\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Thomas Aujoux\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\inspect.py:3211\u001b[0m, in \u001b[0;36mSignature.bind\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbind\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m/\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   3207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Get a BoundArguments object, that maps the passed `args`\u001b[39;00m\n\u001b[0;32m   3208\u001b[0m \u001b[39m    and `kwargs` to the function's signature.  Raises `TypeError`\u001b[39;00m\n\u001b[0;32m   3209\u001b[0m \u001b[39m    if the passed arguments can not be bound.\u001b[39;00m\n\u001b[0;32m   3210\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3211\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bind(args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\Thomas Aujoux\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\inspect.py:3200\u001b[0m, in \u001b[0;36mSignature._bind\u001b[1;34m(self, args, kwargs, partial)\u001b[0m\n\u001b[0;32m   3198\u001b[0m         arguments[kwargs_param\u001b[39m.\u001b[39mname] \u001b[39m=\u001b[39m kwargs\n\u001b[0;32m   3199\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 3200\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m   3201\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mgot an unexpected keyword argument \u001b[39m\u001b[39m{arg!r}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   3202\u001b[0m                 arg\u001b[39m=\u001b[39m\u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(kwargs))))\n\u001b[0;32m   3204\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_arguments_cls(\u001b[39mself\u001b[39m, arguments)\n",
      "\u001b[1;31mTypeError\u001b[0m: got an unexpected keyword argument 'average'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = nbModel_grid.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred), \": is the confusion matrix\")\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred, average=\"weighted\"), \": is the accuracy score\")\n",
    "from sklearn.metrics import precision_score\n",
    "#print(precision_score(y_test, y_pred), \": is the precision score\")\n",
    "from sklearn.metrics import recall_score\n",
    "print(recall_score(y_test, y_pred, average=\"weighted\"), \": is the recall score\")\n",
    "from sklearn.metrics import f1_score\n",
    "print(f1_score(y_test, y_pred, average=\"weighted\"), \": is the f1 score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9304107909258124 : is the recall score\n",
      "0.9329957886293471 : is the f1 score\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import precision_score\n",
    "#print(precision_score(y_test, y_pred), \": is the precision score\")\n",
    "from sklearn.metrics import recall_score\n",
    "print(recall_score(y_test, y_pred, average=\"weighted\"), \": is the recall score\")\n",
    "from sklearn.metrics import f1_score\n",
    "print(f1_score(y_test, y_pred, average=\"weighted\"), \": is the f1 score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Produits traiteurs frais', 'Plats cuisines ambiants',\n",
       "       'Plats cuisines ambiants', ..., 'Plats cuisines frais',\n",
       "       'Plats cuisines surgeles', 'Snacking surgele'], dtype='<U45')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_mnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_mnb = MultinomialNB()\n",
    "clf_mnb = clf_mnb.fit(X_train, y_train)\n",
    "y_pred_mnb = clf_mnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for axis 1 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m clf_mnb \u001b[39m=\u001b[39m CategoricalNB()\n\u001b[0;32m      3\u001b[0m clf_mnb \u001b[39m=\u001b[39m clf_mnb\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m----> 4\u001b[0m y_pred_mnb \u001b[39m=\u001b[39m clf_mnb\u001b[39m.\u001b[39;49mpredict(X_test)\n",
      "File \u001b[1;32mc:\\Users\\Thomas Aujoux\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\naive_bayes.py:106\u001b[0m, in \u001b[0;36m_BaseNB.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    104\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m    105\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_X(X)\n\u001b[1;32m--> 106\u001b[0m jll \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_joint_log_likelihood(X)\n\u001b[0;32m    107\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_[np\u001b[39m.\u001b[39margmax(jll, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)]\n",
      "File \u001b[1;32mc:\\Users\\Thomas Aujoux\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\naive_bayes.py:1530\u001b[0m, in \u001b[0;36mCategoricalNB._joint_log_likelihood\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1528\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_):\n\u001b[0;32m   1529\u001b[0m     indices \u001b[39m=\u001b[39m X[:, i]\n\u001b[1;32m-> 1530\u001b[0m     jll \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeature_log_prob_[i][:, indices]\u001b[39m.\u001b[39mT\n\u001b[0;32m   1531\u001b[0m total_ll \u001b[39m=\u001b[39m jll \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_log_prior_\n\u001b[0;32m   1532\u001b[0m \u001b[39mreturn\u001b[39;00m total_ll\n",
      "\u001b[1;31mIndexError\u001b[0m: index 2 is out of bounds for axis 1 with size 2"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB\n",
    "clf_mnb = CategoricalNB()\n",
    "clf_mnb = clf_mnb.fit(X_train, y_train)\n",
    "y_pred_mnb = clf_mnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Glaces et sorbets', 'Sauces condimentaires',\n",
       "       'Produits laitiers et desserts frais', ..., 'Glaces et sorbets',\n",
       "       'Produits laitiers et desserts frais',\n",
       "       'Produits transformes a base de pomme de terre'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "mat = confusion_matrix(y_test, y_pred_mnb, labels=y_train.values)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=y_train.values, yticklabels=y_train.values)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix,ConfusionMatrixDisplay,f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8923206621704476\n",
      "F1 Score: 0.8922367361212168\n"
     ]
    }
   ],
   "source": [
    "accuray = accuracy_score(y_pred_mnb, y_test)\n",
    "f1 = f1_score(y_pred_mnb, y_test, average=\"weighted\")\n",
    "\n",
    "print(\"Accuracy:\", accuray)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_category(s, train=train, model=model):\n",
    "    pred = model.predict([s])\n",
    "    return train.target_names[pred[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "predict_category('sending a payload to the ISS')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85.33108522378909\n",
      "F1 Score: 81.30978080986513\n",
      "Precision: 89.2926639219838\n",
      "Recall: 78.49630124315333\n",
      "                                               precision    recall  f1-score   support\n",
      "\n",
      "       Aliments infantiles de diversification       0.98      0.65      0.78       190\n",
      "                          Aperitifs a croquer       0.94      0.79      0.85       337\n",
      "                           Barres cerealieres       1.00      0.47      0.64        72\n",
      "              Biscuits et gateaux industriels       0.82      0.98      0.89      1333\n",
      "        Boissons Rafraichissantes Sans Alcool       0.79      0.91      0.85       420\n",
      "                         Bouillons et potages       0.89      0.83      0.86       279\n",
      "              Cereales pour le petit dejeuner       0.83      0.93      0.88       285\n",
      "                                  Charcuterie       0.96      0.96      0.96       538\n",
      "              Chocolat et produits chocolates       0.98      0.83      0.90       304\n",
      "                                     Compotes       0.90      0.94      0.92       368\n",
      "                                  Confiseries       0.95      0.78      0.85       236\n",
      "                                   Confitures       0.94      0.98      0.96       263\n",
      "                          Conserves de fruits       0.99      0.78      0.87       118\n",
      "                                     Fromages       0.93      0.90      0.91       374\n",
      "                            Glaces et sorbets       0.86      0.97      0.91       641\n",
      "                               Jus et nectars       0.96      0.79      0.87       456\n",
      "                             Laits infantiles       0.93      0.93      0.93        27\n",
      "                                   Margarines       1.00      0.70      0.82        46\n",
      "      Panification croustillante et moelleuse       0.83      0.85      0.84       632\n",
      "                      Plats cuisines ambiants       0.83      0.89      0.86       950\n",
      "                         Plats cuisines frais       0.76      0.59      0.66       430\n",
      "                      Plats cuisines surgeles       0.74      0.87      0.80      1239\n",
      "                   Preparations pour desserts       1.00      0.04      0.07       110\n",
      "          Produits laitiers et desserts frais       0.92      0.93      0.92      1189\n",
      "                     Produits traiteurs frais       0.80      0.77      0.78       680\n",
      "Produits transformes a base de pomme de terre       0.98      0.81      0.88       294\n",
      "                               Sauces chaudes       0.90      0.44      0.59       173\n",
      "                        Sauces condimentaires       0.93      0.87      0.90       250\n",
      "      Sirops et boissons concentrees a diluer       0.88      0.60      0.72       172\n",
      "                             Snacking surgele       0.76      0.88      0.81       450\n",
      "           Viennoiseries et desserts surgeles       0.72      0.69      0.70       192\n",
      "\n",
      "                                     accuracy                           0.85     13048\n",
      "                                    macro avg       0.89      0.78      0.81     13048\n",
      "                                 weighted avg       0.86      0.85      0.85     13048\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix,ConfusionMatrixDisplay,f1_score, precision_score, recall_score, classification_report\n",
    "\n",
    "#Naive Bayes\n",
    "clf = MultinomialNB().fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy:\",accuracy_score(y_test,y_pred)*100)\n",
    "print(\"F1 Score:\",f1_score(y_test, y_pred, average=\"macro\")*100)\n",
    "print(\"Precision:\",precision_score(y_test, y_pred, average=\"macro\")*100)\n",
    "print(\"Recall:\",recall_score(y_test, y_pred, average=\"macro\")*100)\n",
    "print (classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function that handles sample splitting, model fitting and report printing \n",
    "def mfunc(X, y, typ):\n",
    "    \n",
    "    # Create training and testing samples\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "    # Fit the model\n",
    "    model = typ\n",
    "    clf = model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict class labels on a test data\n",
    "    pred_labels = model.predict(X_test)\n",
    "\n",
    "    # Print model attributes \n",
    "    print('Classes: ', clf.classes_) # class labels known to the classifier\n",
    "    if str(typ)=='GaussianNB()':\n",
    "        print('Class Priors: ',clf.class_prior_) # prior probability of each class.\n",
    "    else: \n",
    "        print('Class Log Priors: ',clf.class_log_prior_) # log prior probability of each class.\n",
    "        \n",
    "    # Use score method to get accuracy of the model\n",
    "    print('--------------------------------------------------------')\n",
    "    score = model.score(X_test, y_test)\n",
    "    print('Accuracy Score: ', score)\n",
    "    print('--------------------------------------------------------')\n",
    "    \n",
    "    # Look at classification report to evaluate the model\n",
    "    print(classification_report(y_test, pred_labels))\n",
    "    \n",
    "    # Return relevant data for chart plotting\n",
    "    return X_train, X_test, y_train, y_test, clf, pred_labels\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 5 is out of bounds for axis 1 with size 5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_train, X_test, y_train, y_test, clf, pred_labels \u001b[39m=\u001b[39m mfunc(X_train, y_train, CategoricalNB())\n",
      "Cell \u001b[1;32mIn[6], line 12\u001b[0m, in \u001b[0;36mmfunc\u001b[1;34m(X, y, typ)\u001b[0m\n\u001b[0;32m      9\u001b[0m clf \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     11\u001b[0m \u001b[39m# Predict class labels on a test data\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m pred_labels \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(X_test)\n\u001b[0;32m     14\u001b[0m \u001b[39m# Print model attributes \u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mClasses: \u001b[39m\u001b[39m'\u001b[39m, clf\u001b[39m.\u001b[39mclasses_) \u001b[39m# class labels known to the classifier\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Thomas Aujoux\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\naive_bayes.py:106\u001b[0m, in \u001b[0;36m_BaseNB.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    104\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m    105\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_X(X)\n\u001b[1;32m--> 106\u001b[0m jll \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_joint_log_likelihood(X)\n\u001b[0;32m    107\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_[np\u001b[39m.\u001b[39margmax(jll, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)]\n",
      "File \u001b[1;32mc:\\Users\\Thomas Aujoux\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\naive_bayes.py:1530\u001b[0m, in \u001b[0;36mCategoricalNB._joint_log_likelihood\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1528\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_):\n\u001b[0;32m   1529\u001b[0m     indices \u001b[39m=\u001b[39m X[:, i]\n\u001b[1;32m-> 1530\u001b[0m     jll \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeature_log_prob_[i][:, indices]\u001b[39m.\u001b[39mT\n\u001b[0;32m   1531\u001b[0m total_ll \u001b[39m=\u001b[39m jll \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_log_prior_\n\u001b[0;32m   1532\u001b[0m \u001b[39mreturn\u001b[39;00m total_ll\n",
      "\u001b[1;31mIndexError\u001b[0m: index 5 is out of bounds for axis 1 with size 5"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, clf, pred_labels = mfunc(X_train, y_train, CategoricalNB())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
