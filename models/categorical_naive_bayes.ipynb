{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "from sklearn.naive_bayes import CategoricalNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multunomiale Naive Bayes\n",
    "\n",
    "## I) Theory\n",
    "\n",
    "Naive Bayes models are a type of classification algorithm that is fast, simple and is suitable for classification probleme because the data set is high-dimensional.\n",
    "This model will be a baseline for our Multi-Class classification problem since they are so fast and have so few configurable parameters.\n",
    "\n",
    "### 1) Equations\n",
    "\n",
    "The model is based on Bayes theorem, an equation that describes the relationship between conditional probabilities of statistical quantities.\n",
    "We want to find the probability of a Sector $S$ given certain observed features in Bayesian classification, which we can write as $P(S|rm features)$.\n",
    "We have with the Bayes theorem that :\n",
    "\n",
    "$$\n",
    "P(S~|~{\\rm features}) = \\frac{P({\\rm features}~|~S)P(S)}{P({\\rm features})}\n",
    "$$\n",
    "\n",
    "If we want to choose between two labels, let's call them $S_1$ and $S_2$, one technique to do so is to compute the ratio of their posterior probabilities:\n",
    "\n",
    "$$\n",
    "\\frac{P(S_1~|~{\\rm features})}{P(S_2~|~{\\rm features})} = \\frac{P({\\rm features}~|~S_1)}{P({\\rm features}~|~S_2)}\\frac{P(S_1)}{P(S_2)}\n",
    "$$\n",
    "\n",
    "\n",
    "All we need now is a model that can calculate $P(rm features|S_i)$ for each label.\n",
    "A *generative model* is one that specifies specifies the hypothetical random process that generates the data.\n",
    "The fundamental component of training a Bayesian classifier is specifying this generative model for each label.\n",
    "The general version of such a training phase is a challenging operation, but we may simplify it by making some simplifying assumptions about the model's shape.\n",
    "\n",
    "In the next part of this notebook we will use Categorical Naive Bayes because it's the one that best fits our problem.\n",
    "\n",
    "### 2) Categorical Naive Bayes\n",
    "\n",
    "It is assumed that the features are generated by a basic multinomial distribution.\n",
    "Because the multinomial distribution explains the chance of detecting counts across several categories, categorical naive Bayes is best suited for features that represent counts or count rates.\n",
    "\n",
    "## II) Advantages and Drawbacks\n",
    "\n",
    "Advantages :\n",
    "- This algorithm works very fast and can easily predict the class of a test dataset. \n",
    "- For very high-dimensional data, when model complexity is less important\n",
    "- Naive Bayes classifier performs better than other models with less training data if the assumption of independence of features holds. \n",
    "- They provide straightforward probabilistic prediction.\n",
    "- They are often easily interpretable.\n",
    "- They have few (if any) tunable parameters.\n",
    "\n",
    "These advantages mean a naive Bayes classifier is often a good choice as an initial baseline classification.\n",
    "\n",
    "!!!!!!!! A réécrire !!!!!!!\n",
    "The final two statements appear to be unrelated, but they are: as the dimensionality of a dataset increases, it becomes far less likely that any two points will be located near together (after all, they must be close in *every single dimension* to be close overall).\n",
    "This suggests that clusters in high dimensions are more separated than clusters in low dimensions on average, provided the new dimensions add information.\n",
    "As a result, as the dimensionality increases, simplest classifiers like the ones mentioned here tend to perform as well as or better than more complicated classifiers: provided you have enough data, even a simple model can be very strong.\n",
    "!!!!!!!! A réécrire !!!!!!!\n",
    "\n",
    "drawbacks :\n",
    "- If your test data set contains a categorical variable from a category that was not present in the training data set, the Naive Bayes model will assign it zero probability and will be unable to make predictions. This phenomena is known as 'Zero Frequency,' and it must be solved using a smoothing process.\n",
    "- This approach is also known for being a poor estimator. As a result, you shouldn't take the 'predict_proba' probability results too seriously. \n",
    "- It is assumed that all of the features are self-contained. While it may seem excellent in principle, it is rare to find a collection of independent traits in practice. \n",
    "\n",
    "## II) Python implementation\n",
    "\n",
    "As this model represents the baseline, we're going to detail each important step so that we can automate this part for the other models.\n",
    "\n",
    "As this model is just a baseline, we won't go into the details of Grid Research or Cross Validation. Indeed, this model will never be used in the future, as our data set is so imbalanced that certain probabilities are likely to be zero if they are not in the train set.\n",
    "\n",
    "### 1) Importing and setting up data\n",
    "\n",
    "We'll start by importing the data and structuring it for further processing, by removing columns of no interest and rows without labels. Then we'll separate the dataset into two parts: the training part, which represents 80% of the data we have, and the test part, for the remaining 20%.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\Thomas Aujoux\\Documents\\GitHub\\food-classification\\Data_Preprocessing\\data_clean\\clean.csv')\n",
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "df = df.drop(labels=22426, axis=0)\n",
    "\n",
    "y = df[[\"Secteur\"]]\n",
    "df_features = df.drop([\"Code_produit\", \"Secteur\", \"Famille\"], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_features, y, test_size=0.2, shuffle=True, random_state=42)\n",
    "\n",
    "X_train.to_csv(r'C:\\Users\\Thomas Aujoux\\Documents\\GitHub\\food-classification\\models\\data\\X_train.csv')\n",
    "X_test.to_csv(r'C:\\Users\\Thomas Aujoux\\Documents\\GitHub\\food-classification\\models\\data\\X_test.csv')\n",
    "y_train.to_csv(r'C:\\Users\\Thomas Aujoux\\Documents\\GitHub\\food-classification\\models\\data\\y_train.csv')\n",
    "y_test.to_csv(r'C:\\Users\\Thomas Aujoux\\Documents\\GitHub\\food-classification\\models\\data\\y_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Hyperparameters tuning\n",
    "\n",
    "Despite the fact that this model only represents a baseline for our project, and that we know in advance, given the presence of an imbalanced dataset, that certain sectors will have a zero probability of appearing, we know that this model will not be used in the future. However, the naive bayes classifier will be used to introduce the various concepts and algorithms we'll be using later.\n",
    "There are different hyperparameters that needs tuning to get best fit for our data.\n",
    "\n",
    "- alpha:\n",
    "It accepts float values that represent the additive smoothing parameter alpha. A value of 0.0 indicates that there is no smoothing. This parameter's default value is 1.0.\n",
    "\n",
    "- fit_prior:\n",
    "It receives a boolean value indicating whether or not to learn prior class probability.\n",
    "\n",
    "- min_categories:\n",
    "It provides an integer or an array of shape (n_features,) defining the minimum categories to consider for each feature.\n",
    "\n",
    "- class_prior:\n",
    "class_prior accepts arrays of the form (n_classes,) which specify the prior probability of target classes.\n",
    "\n",
    "\n",
    "### 3) Study of the various hyperparameters\n",
    "\n",
    "Next, we'll look at each of the hyperparameters to understand the consequences of changing them on the model.\n",
    "\n",
    "#### Alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "opt_table_estimators_accuracy=list()\n",
    "opt_table_estimators_f1=list()\n",
    "list_para = [0.01, 0.1, 0.5, 1.0, 10.0, ]\n",
    "\n",
    "for i in list_para:\n",
    "    model = CategoricalNB(alpha=i,min_categories=31)\n",
    "    model.fit(X_train,y_train.values.ravel())\n",
    "    output=model.predict(X_test)\n",
    "    opt_table_estimators_accuracy.append(metrics.accuracy_score(y_test, output))\n",
    "    opt_table_estimators_f1.append(metrics.f1_score(y_test, output, average='macro'))\n",
    "plt.plot(range(min, max, steps), opt_table_estimators_accuracy)\n",
    "plt.plot(range(min, max, steps), opt_table_estimators_f1)\n",
    "plt.xlabel('Number of trees')\n",
    "plt.ylabel('Random Forest Score')\n",
    "plt.title('Random Forest Score VS Number of trees (5 features)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Automatisation of Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = r'C:\\Users\\Thomas Aujoux\\Documents\\GitHub\\food-classification\\Data_Preprocessing\\data_clean\\clean.csv'\n",
    "\n",
    "params = {'alpha': [0.01, 0.1, 0.5, 1.0, 10.0, ],\n",
    "          'fit_prior': [True, False],\n",
    "          'min_categories': [18, 25, 30],\n",
    "          'class_prior': [None, [0.1,]* len(n_classes),]\n",
    "         }# Create a based model\n",
    "\n",
    "def model_best_param(PATH, model, params):\n",
    "    \n",
    "    df = pd.read_csv(PATH)\n",
    "    df = df.drop('Unnamed: 0', axis=1)\n",
    "    df = df.drop(labels=22426, axis=0)\n",
    "\n",
    "    y = df[[\"Secteur\"]]\n",
    "    df_features = df.drop([\"Code_produit\", \"Secteur\", \"Famille\"], axis=1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_features, y, test_size=0.2, shuffle=True, random_state=42)\n",
    "\n",
    "    pipe_nb = make_pipeline(\n",
    "    model()\n",
    "    )\n",
    "    grid_search = GridSearchCV(estimator=model(), param_grid=params, verbose=2, cv=5, n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "    output = grid_search.predict(X_test)\n",
    "\n",
    "    return(grid_search.best_params_, metrics.accuracy_score(y_test, output), metrics.f1_score(y_test, output, average='macro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 60 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thomas Aujoux\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CategoricalNB(alpha=0.1, fit_prior=False, min_categories=18)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "params = {'alpha': [0.01, 0.1, 0.5, 1.0, 10.0, ],\n",
    "          'fit_prior': [True, False],\n",
    "          'min_categories': [18, 25, 30],\n",
    "          'class_prior': [None, [0.1,]* 31,]\n",
    "         }\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "nbModel_grid = GridSearchCV(estimator=CategoricalNB(), param_grid=params, verbose=2, cv=2, n_jobs=-1)\n",
    "nbModel_grid.fit(X_train, y_train)\n",
    "print(nbModel_grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m nbModel_grid\u001b[39m.\u001b[39;49mscore(X_test, y_test)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:471\u001b[0m, in \u001b[0;36mBaseSearchCV.score\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    468\u001b[0m     \u001b[39mreturn\u001b[39;00m scorer(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_estimator_, X, y)\n\u001b[0;32m    470\u001b[0m \u001b[39m# callable\u001b[39;00m\n\u001b[1;32m--> 471\u001b[0m score \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscorer_(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbest_estimator_, X, y)\n\u001b[0;32m    472\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmultimetric_:\n\u001b[0;32m    473\u001b[0m     score \u001b[39m=\u001b[39m score[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrefit]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_scorer.py:527\u001b[0m, in \u001b[0;36m_PassthroughScorer.__call__\u001b[1;34m(self, estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m    525\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    526\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Method that wraps estimator.score\"\"\"\u001b[39;00m\n\u001b[1;32m--> 527\u001b[0m     \u001b[39mreturn\u001b[39;00m estimator\u001b[39m.\u001b[39;49mscore(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:705\u001b[0m, in \u001b[0;36mClassifierMixin.score\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    681\u001b[0m \u001b[39mReturn the mean accuracy on the given test data and labels.\u001b[39;00m\n\u001b[0;32m    682\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    701\u001b[0m \u001b[39m    Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\u001b[39;00m\n\u001b[0;32m    702\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    703\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m accuracy_score\n\u001b[1;32m--> 705\u001b[0m \u001b[39mreturn\u001b[39;00m accuracy_score(y, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(X), sample_weight\u001b[39m=\u001b[39msample_weight)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\naive_bayes.py:102\u001b[0m, in \u001b[0;36m_BaseNB.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    100\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m    101\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_X(X)\n\u001b[1;32m--> 102\u001b[0m jll \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_joint_log_likelihood(X)\n\u001b[0;32m    103\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_[np\u001b[39m.\u001b[39margmax(jll, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\naive_bayes.py:1526\u001b[0m, in \u001b[0;36mCategoricalNB._joint_log_likelihood\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1524\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_):\n\u001b[0;32m   1525\u001b[0m     indices \u001b[39m=\u001b[39m X[:, i]\n\u001b[1;32m-> 1526\u001b[0m     jll \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeature_log_prob_[i][:, indices]\u001b[39m.\u001b[39mT\n\u001b[0;32m   1527\u001b[0m total_ll \u001b[39m=\u001b[39m jll \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_log_prior_\n\u001b[0;32m   1528\u001b[0m \u001b[39mreturn\u001b[39;00m total_ll\n",
      "\u001b[1;31mIndexError\u001b[0m: index 1 is out of bounds for axis 1 with size 1"
     ]
    }
   ],
   "source": [
    "nbModel_grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 152    0    0    1    0    0    0    0    0   24    0    0    0    0\n",
      "     0    3    0    0    0    4    0    1    1    1    0    2    1    0\n",
      "     0    0    0]\n",
      " [   0  297    0    8    0    0    0    0    2    1    0    0    0    1\n",
      "     0    0    0    0   16    0    0    0   10    0    0    2    0    0\n",
      "     0    0    0]\n",
      " [   0    0   67    0    0    0    5    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0]\n",
      " [   0    0    1 1298    1    0    0    0    4    0    0    0    0    2\n",
      "     0    0    0    0    7    0    0    0   17    2    1    0    0    0\n",
      "     0    0    0]\n",
      " [   0    0    0    0  368    0    0    0    0    1    1    0    0    0\n",
      "     0   39    0    0    0    0    0    0    5    5    0    0    0    0\n",
      "     1    0    0]\n",
      " [   0    0    0    0    1  263    0    0    0    0    0    0    0    0\n",
      "     0    1    0    0    0    2    0    3    0    0    2    5    2    0\n",
      "     0    0    0]\n",
      " [   0    1    5    4    0    0  258    0    6    0    0    0    0    0\n",
      "     0    0    0    0    2    0    0    0    8    1    0    0    0    0\n",
      "     0    0    0]\n",
      " [   0    0    0    0    0    0    0  532    0    0    0    0    0    0\n",
      "     0    0    0    0    0    1    0    0    4    1    0    0    0    0\n",
      "     0    0    0]\n",
      " [   0    1    0    1    0    0    1    0  292    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    7    1    0    0    0    0\n",
      "     0    0    1]\n",
      " [   1    0    0    1    0    0    0    0    0  353    0    2    3    0\n",
      "     0    1    0    0    0    0    0    0    2    3    0    0    0    0\n",
      "     0    0    2]\n",
      " [   0    0    0    0    0    0    0    0    7    0  204    0    0    0\n",
      "     2    8    0    0    0    0    0    0    7    1    0    0    0    0\n",
      "     7    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0  257    2    0\n",
      "     0    1    0    0    0    0    0    0    0    3    0    0    0    0\n",
      "     0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    1    0    1   99    0\n",
      "     0    9    0    0    0    0    0    0    1    7    0    0    0    0\n",
      "     0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0  349\n",
      "     0    5    0    0    0    0    0    1    6   11    1    0    0    0\n",
      "     0    1    0]\n",
      " [   0    0    1    1    1    0    0    0    3    3    0    0    2    0\n",
      "   609    6    0    0    0    0    0    0    7    7    0    0    0    0\n",
      "     0    0    1]\n",
      " [   1    0    0    0    5    0    0    0    0    2    0    0    1    0\n",
      "     0  443    0    0    0    0    0    0    2    2    0    0    0    0\n",
      "     0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0   27    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    1    0   42    1    0    0    0    1    1    0    0    0    0\n",
      "     0    0    0]\n",
      " [   0    1    1   23    0    0    1    0    1    0    0    0    0    0\n",
      "     0    1    0    0  586    0    0    1   16    1    0    0    0    0\n",
      "     0    0    0]\n",
      " [   0    1    0    0    0    0    0    2    0    0    0    0    0    1\n",
      "     0    2    0    0    0  891    3   16   14    0    2    5   12    1\n",
      "     0    0    0]\n",
      " [   0    1    0    3    0    0    0    2    0    1    0    0    0    1\n",
      "     0    0    0    0    0    5  376   31    3    1    3    2    0    0\n",
      "     0    1    0]\n",
      " [   0    0    0    0    0    2    0    5    0    0    0    0    0    1\n",
      "     0    2    0    0    6    8   23 1158    4    0    5   19    3    1\n",
      "     0    2    0]\n",
      " [   0    0    0   14    0    0    0    0    1    0    0    0    1    0\n",
      "     0    0    0    0    0    0    0    0   90    2    1    0    0    0\n",
      "     0    0    1]\n",
      " [   0    0    0    5    0    0    0    0    2    0    2    2    0    5\n",
      "     1    3    0    2    2    0    0    0   10 1154    0    0    0    1\n",
      "     0    0    0]\n",
      " [   0    0    0   13    0    0    0    1    0    1    0    0    0    2\n",
      "     0    5    0    1   12    3    0    8   21    6  586    1    2    8\n",
      "     0    9    1]\n",
      " [   0    3    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    1    0    0    0    0    0    1    3    0    0  286    0    0\n",
      "     0    0    0]\n",
      " [   0    0    0    0    0    1    0    0    0    0    0    0    0    0\n",
      "     0    1    0    0    0    2    0    1   13    4    0    0  150    1\n",
      "     0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    1    0    1    0   10  238\n",
      "     0    0    0]\n",
      " [   0    0    0    0    4    0    0    0    0    0    0    0    0    0\n",
      "     0   28    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "   140    0    0]\n",
      " [   0    0    0    1    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    2    0    1   11    0    0   12    0    0    0\n",
      "     0  422    1]\n",
      " [   0    0    0   16    0    0    0    0    2    1    0    0    0    0\n",
      "     0    0    0    0    8    0    0    0   10    1    0    0    0    1\n",
      "     0    0  153]] : is the confusion matrix\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "got an unexpected keyword argument 'average'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mprint\u001b[39m(confusion_matrix(y_test, y_pred), \u001b[39m\"\u001b[39m\u001b[39m: is the confusion matrix\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m accuracy_score\n\u001b[1;32m----> 7\u001b[0m \u001b[39mprint\u001b[39m(accuracy_score(y_test, y_pred, average\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mweighted\u001b[39;49m\u001b[39m\"\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39m: is the accuracy score\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m precision_score\n\u001b[0;32m      9\u001b[0m \u001b[39m#print(precision_score(y_test, y_pred), \": is the precision score\")\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Thomas Aujoux\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:175\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    172\u001b[0m func_sig \u001b[39m=\u001b[39m signature(func)\n\u001b[0;32m    174\u001b[0m \u001b[39m# Map *args/**kwargs to the function signature\u001b[39;00m\n\u001b[1;32m--> 175\u001b[0m params \u001b[39m=\u001b[39m func_sig\u001b[39m.\u001b[39;49mbind(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    176\u001b[0m params\u001b[39m.\u001b[39mapply_defaults()\n\u001b[0;32m    178\u001b[0m \u001b[39m# ignore self/cls and positional/keyword markers\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Thomas Aujoux\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\inspect.py:3211\u001b[0m, in \u001b[0;36mSignature.bind\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbind\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m/\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   3207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Get a BoundArguments object, that maps the passed `args`\u001b[39;00m\n\u001b[0;32m   3208\u001b[0m \u001b[39m    and `kwargs` to the function's signature.  Raises `TypeError`\u001b[39;00m\n\u001b[0;32m   3209\u001b[0m \u001b[39m    if the passed arguments can not be bound.\u001b[39;00m\n\u001b[0;32m   3210\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3211\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bind(args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\Thomas Aujoux\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\inspect.py:3200\u001b[0m, in \u001b[0;36mSignature._bind\u001b[1;34m(self, args, kwargs, partial)\u001b[0m\n\u001b[0;32m   3198\u001b[0m         arguments[kwargs_param\u001b[39m.\u001b[39mname] \u001b[39m=\u001b[39m kwargs\n\u001b[0;32m   3199\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 3200\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m   3201\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mgot an unexpected keyword argument \u001b[39m\u001b[39m{arg!r}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   3202\u001b[0m                 arg\u001b[39m=\u001b[39m\u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(kwargs))))\n\u001b[0;32m   3204\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_arguments_cls(\u001b[39mself\u001b[39m, arguments)\n",
      "\u001b[1;31mTypeError\u001b[0m: got an unexpected keyword argument 'average'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = nbModel_grid.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred), \": is the confusion matrix\")\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred, average=\"weighted\"), \": is the accuracy score\")\n",
    "from sklearn.metrics import precision_score\n",
    "#print(precision_score(y_test, y_pred), \": is the precision score\")\n",
    "from sklearn.metrics import recall_score\n",
    "print(recall_score(y_test, y_pred, average=\"weighted\"), \": is the recall score\")\n",
    "from sklearn.metrics import f1_score\n",
    "print(f1_score(y_test, y_pred, average=\"weighted\"), \": is the f1 score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9304107909258124 : is the recall score\n",
      "0.9329957886293471 : is the f1 score\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import precision_score\n",
    "#print(precision_score(y_test, y_pred), \": is the precision score\")\n",
    "from sklearn.metrics import recall_score\n",
    "print(recall_score(y_test, y_pred, average=\"weighted\"), \": is the recall score\")\n",
    "from sklearn.metrics import f1_score\n",
    "print(f1_score(y_test, y_pred, average=\"weighted\"), \": is the f1 score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Produits traiteurs frais', 'Plats cuisines ambiants',\n",
       "       'Plats cuisines ambiants', ..., 'Plats cuisines frais',\n",
       "       'Plats cuisines surgeles', 'Snacking surgele'], dtype='<U45')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_mnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_mnb = MultinomialNB()\n",
    "clf_mnb = clf_mnb.fit(X_train, y_train)\n",
    "y_pred_mnb = clf_mnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thomas Aujoux\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m clf_mnb \u001b[39m=\u001b[39m CategoricalNB()\n\u001b[0;32m      3\u001b[0m clf_mnb \u001b[39m=\u001b[39m clf_mnb\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m----> 4\u001b[0m y_pred_mnb \u001b[39m=\u001b[39m clf_mnb\u001b[39m.\u001b[39;49mpredict(X_test)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\naive_bayes.py:102\u001b[0m, in \u001b[0;36m_BaseNB.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    100\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m    101\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_X(X)\n\u001b[1;32m--> 102\u001b[0m jll \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_joint_log_likelihood(X)\n\u001b[0;32m    103\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_[np\u001b[39m.\u001b[39margmax(jll, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\naive_bayes.py:1526\u001b[0m, in \u001b[0;36mCategoricalNB._joint_log_likelihood\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1524\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_):\n\u001b[0;32m   1525\u001b[0m     indices \u001b[39m=\u001b[39m X[:, i]\n\u001b[1;32m-> 1526\u001b[0m     jll \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeature_log_prob_[i][:, indices]\u001b[39m.\u001b[39mT\n\u001b[0;32m   1527\u001b[0m total_ll \u001b[39m=\u001b[39m jll \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_log_prior_\n\u001b[0;32m   1528\u001b[0m \u001b[39mreturn\u001b[39;00m total_ll\n",
      "\u001b[1;31mIndexError\u001b[0m: index 1 is out of bounds for axis 1 with size 1"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB\n",
    "clf_mnb = CategoricalNB()\n",
    "clf_mnb = clf_mnb.fit(X_train, y_train)\n",
    "y_pred_mnb = clf_mnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Glaces et sorbets', 'Sauces condimentaires',\n",
       "       'Produits laitiers et desserts frais', ..., 'Glaces et sorbets',\n",
       "       'Produits laitiers et desserts frais',\n",
       "       'Produits transformes a base de pomme de terre'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "mat = confusion_matrix(y_test, y_pred_mnb, labels=y_train.values)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=y_train.values, yticklabels=y_train.values)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix,ConfusionMatrixDisplay,f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8501519756838906\n",
      "F1 Score: 0.8525029721038722\n"
     ]
    }
   ],
   "source": [
    "accuray = accuracy_score(y_pred_mnb, y_test)\n",
    "f1 = f1_score(y_pred_mnb, y_test, average=\"weighted\")\n",
    "\n",
    "print(\"Accuracy:\", accuray)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_category(s, train=train, model=model):\n",
    "    pred = model.predict([s])\n",
    "    return train.target_names[pred[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "predict_category('sending a payload to the ISS')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thomas Aujoux\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 82.72036474164133\n",
      "F1 Score: 78.14901526262827\n",
      "Precision: 83.41057508069942\n",
      "Recall: 77.00806782690213\n",
      "                                               precision    recall  f1-score   support\n",
      "\n",
      "       Aliments infantiles de diversification       0.90      0.58      0.71       184\n",
      "                          Aperitifs a croquer       0.82      0.75      0.78       332\n",
      "                           Barres cerealieres       0.97      0.45      0.62        64\n",
      "              Biscuits et gateaux industriels       0.83      0.96      0.89      1346\n",
      "        Boissons Rafraichissantes Sans Alcool       0.84      0.87      0.85       450\n",
      "                         Bouillons et potages       0.89      0.71      0.79       267\n",
      "              Cereales pour le petit dejeuner       0.68      0.95      0.80       255\n",
      "                                  Charcuterie       0.89      0.97      0.93       547\n",
      "              Chocolat et produits chocolates       0.87      0.88      0.87       332\n",
      "                                     Compotes       0.93      0.96      0.94       387\n",
      "                                  Confiseries       0.86      0.79      0.82       253\n",
      "                                   Confitures       0.96      0.97      0.97       253\n",
      "                          Conserves de fruits       0.95      0.84      0.89       111\n",
      "                                     Fromages       0.96      0.95      0.95       354\n",
      "                            Glaces et sorbets       0.90      0.94      0.92       646\n",
      "                               Jus et nectars       0.89      0.91      0.90       503\n",
      "                             Laits infantiles       0.47      0.33      0.39        21\n",
      "                                   Margarines       0.51      0.97      0.67        34\n",
      "      Panification croustillante et moelleuse       0.89      0.84      0.87       651\n",
      "                      Plats cuisines ambiants       0.71      0.78      0.74       912\n",
      "                         Plats cuisines frais       0.73      0.37      0.50       468\n",
      "                      Plats cuisines surgeles       0.67      0.85      0.75      1192\n",
      "                   Preparations pour desserts       1.00      0.29      0.45       113\n",
      "          Produits laitiers et desserts frais       0.94      0.92      0.93      1224\n",
      "                     Produits traiteurs frais       0.86      0.58      0.69       685\n",
      "Produits transformes a base de pomme de terre       0.91      0.93      0.92       295\n",
      "                               Sauces chaudes       0.91      0.47      0.62       180\n",
      "                        Sauces condimentaires       0.82      0.94      0.87       250\n",
      "      Sirops et boissons concentrees a diluer       0.89      0.74      0.81       198\n",
      "                             Snacking surgele       0.69      0.77      0.73       441\n",
      "           Viennoiseries et desserts surgeles       0.74      0.60      0.66       212\n",
      "\n",
      "                                     accuracy                           0.83     13160\n",
      "                                    macro avg       0.83      0.77      0.78     13160\n",
      "                                 weighted avg       0.84      0.83      0.82     13160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix,ConfusionMatrixDisplay,f1_score, precision_score, recall_score, classification_report\n",
    "\n",
    "#Naive Bayes\n",
    "clf = MultinomialNB().fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy:\",accuracy_score(y_test,y_pred)*100)\n",
    "print(\"F1 Score:\",f1_score(y_test, y_pred, average=\"macro\")*100)\n",
    "print(\"Precision:\",precision_score(y_test, y_pred, average=\"macro\")*100)\n",
    "print(\"Recall:\",recall_score(y_test, y_pred, average=\"macro\")*100)\n",
    "print (classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function that handles sample splitting, model fitting and report printing \n",
    "def mfunc(X, y, typ):\n",
    "    \n",
    "    # Create training and testing samples\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "    # Fit the model\n",
    "    model = typ\n",
    "    clf = model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict class labels on a test data\n",
    "    pred_labels = model.predict(X_test)\n",
    "\n",
    "    # Print model attributes \n",
    "    print('Classes: ', clf.classes_) # class labels known to the classifier\n",
    "    if str(typ)=='GaussianNB()':\n",
    "        print('Class Priors: ',clf.class_prior_) # prior probability of each class.\n",
    "    else: \n",
    "        print('Class Log Priors: ',clf.class_log_prior_) # log prior probability of each class.\n",
    "        \n",
    "    # Use score method to get accuracy of the model\n",
    "    print('--------------------------------------------------------')\n",
    "    score = model.score(X_test, y_test)\n",
    "    print('Accuracy Score: ', score)\n",
    "    print('--------------------------------------------------------')\n",
    "    \n",
    "    # Look at classification report to evaluate the model\n",
    "    print(classification_report(y_test, pred_labels))\n",
    "    \n",
    "    # Return relevant data for chart plotting\n",
    "    return X_train, X_test, y_train, y_test, clf, pred_labels\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thomas Aujoux\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_train, X_test, y_train, y_test, clf, pred_labels \u001b[39m=\u001b[39m mfunc(X_train, y_train, CategoricalNB())\n",
      "Cell \u001b[1;32mIn[18], line 12\u001b[0m, in \u001b[0;36mmfunc\u001b[1;34m(X, y, typ)\u001b[0m\n\u001b[0;32m      9\u001b[0m clf \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     11\u001b[0m \u001b[39m# Predict class labels on a test data\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m pred_labels \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(X_test)\n\u001b[0;32m     14\u001b[0m \u001b[39m# Print model attributes \u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mClasses: \u001b[39m\u001b[39m'\u001b[39m, clf\u001b[39m.\u001b[39mclasses_) \u001b[39m# class labels known to the classifier\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\naive_bayes.py:102\u001b[0m, in \u001b[0;36m_BaseNB.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    100\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m    101\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_X(X)\n\u001b[1;32m--> 102\u001b[0m jll \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_joint_log_likelihood(X)\n\u001b[0;32m    103\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_[np\u001b[39m.\u001b[39margmax(jll, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\naive_bayes.py:1526\u001b[0m, in \u001b[0;36mCategoricalNB._joint_log_likelihood\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1524\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_):\n\u001b[0;32m   1525\u001b[0m     indices \u001b[39m=\u001b[39m X[:, i]\n\u001b[1;32m-> 1526\u001b[0m     jll \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeature_log_prob_[i][:, indices]\u001b[39m.\u001b[39mT\n\u001b[0;32m   1527\u001b[0m total_ll \u001b[39m=\u001b[39m jll \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_log_prior_\n\u001b[0;32m   1528\u001b[0m \u001b[39mreturn\u001b[39;00m total_ll\n",
      "\u001b[1;31mIndexError\u001b[0m: index 1 is out of bounds for axis 1 with size 1"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, clf, pred_labels = mfunc(X_train, y_train, CategoricalNB())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
